I20240923 18:03:26 193459 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:03:26 193459 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:03:26 193459 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:03:26 193459 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 0
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:03:26 193459 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:03:27 193459 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_base network.
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240923 18:03:27 193459 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240923 18:03:27 193459 dinov2 train.py:303] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240923 18:03:27 193459 dinov2 param_groups.py:54] chunked fsdp
I20240923 18:03:27 193459 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] blocks.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:03:27 193459 dinov2 param_groups.py:64] else code branch
I20240923 18:03:27 193459 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:03:27 193459 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:03:27 193459 dinov2 train.py:102] Schedulers ready.
I20240923 18:03:27 193459 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240923 18:03:27 193459 dinov2 augmentations.py:34] ###################################
I20240923 18:03:27 193459 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240923 18:03:27 193459 dinov2 augmentations.py:36] global_crops_scale: [0.4, 1.0]
I20240923 18:03:27 193459 dinov2 augmentations.py:37] local_crops_scale: [0.1, 0.4]
I20240923 18:03:27 193459 dinov2 augmentations.py:38] local_crops_number: 10
I20240923 18:03:27 193459 dinov2 augmentations.py:39] global_crops_size: 224
I20240923 18:03:27 193459 dinov2 augmentations.py:40] local_crops_size: 98
I20240923 18:03:27 193459 dinov2 augmentations.py:41] ###################################
I20240923 18:03:27 193459 dinov2 loaders.py:80] using dataset: "MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train"
I20240923 18:03:27 193459 dinov2 loaders.py:89] # of dataset samples: 13,823
I20240923 18:03:27 193459 dinov2 loaders.py:122] sampler: sharded infinite
I20240923 18:03:27 193459 dinov2 loaders.py:204] using PyTorch data loader
I20240923 18:03:27 193459 dinov2 loaders.py:219] infinite data loader
I20240923 18:03:27 193459 dinov2 train.py:217] Starting training from iteration 0
W20240923 18:03:33 193459 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()

W20240923 18:03:33 193459 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()

W20240923 18:03:33 193459 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20240923 18:03:33 193459 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20240923 18:03:33 193459 dinov2 helpers.py:102] Training  [     0/160000]  eta: 9 days, 22:23:19  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8144 (14.8144)  dino_local_crops_loss: 10.2595 (10.2595)  dino_global_crops_loss: 1.0260 (1.0260)  koleo_loss: 0.7114 (0.7114)  ibot_loss: 2.8175 (2.8175)  time: 5.363747  data: 3.722965  max mem: 5226
I20240923 18:03:35 193459 dinov2 helpers.py:102] Training  [    10/160000]  eta: 1 day, 7:24:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8064 (14.7452)  dino_local_crops_loss: 10.2595 (10.2563)  dino_global_crops_loss: 1.0260 (1.0256)  koleo_loss: 0.7026 (0.6462)  ibot_loss: 2.8171 (2.8171)  time: 0.706838  data: 0.388461  max mem: 6081
I20240923 18:03:39 193459 dinov2 helpers.py:102] Training  [    20/160000]  eta: 1 day, 0:40:13  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5312 (14.6187)  dino_local_crops_loss: 10.2464 (10.2503)  dino_global_crops_loss: 1.0246 (1.0250)  koleo_loss: 0.4438 (0.5268)  ibot_loss: 2.8167 (2.8166)  time: 0.314723  data: 0.124967  max mem: 6081
I20240923 18:03:43 193459 dinov2 helpers.py:102] Training  [    30/160000]  eta: 22:16:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4346 (14.5479)  dino_local_crops_loss: 10.2416 (10.2472)  dino_global_crops_loss: 1.0242 (1.0247)  koleo_loss: 0.3513 (0.4595)  ibot_loss: 2.8162 (2.8165)  time: 0.388042  data: 0.190823  max mem: 6081
I20240923 18:03:49 193459 dinov2 helpers.py:102] Training  [    40/160000]  eta: 23:16:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.3588 (14.4923)  dino_local_crops_loss: 10.2400 (10.2454)  dino_global_crops_loss: 1.0240 (1.0245)  koleo_loss: 0.2795 (0.4064)  ibot_loss: 2.8155 (2.8160)  time: 0.490569  data: 0.281298  max mem: 6081
I20240923 18:03:52 193459 dinov2 helpers.py:102] Training  [    50/160000]  eta: 21:50:56  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2787 (14.4446)  dino_local_crops_loss: 10.2394 (10.2442)  dino_global_crops_loss: 1.0239 (1.0244)  koleo_loss: 0.1995 (0.3613)  ibot_loss: 2.8126 (2.8147)  time: 0.477182  data: 0.275746  max mem: 6081
I20240923 18:04:56 195171 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:04:56 195171 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:04:56 195171 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:04:56 195171 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ' /mnt/c/Users/kosta/Downloads/dinov2_vitb14_reg4_pretrain.pth'
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 0
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:04:56 195171 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:04:56 195171 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:04:57 195171 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:05:08 195463 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:05:08 195463 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:05:08 195463 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:05:08 195463 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: /mnt/c/Users/kosta/Downloads/dinov2_vitb14_reg4_pretrain.pth
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 0
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:05:08 195463 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:05:08 195463 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:05:09 195463 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:05:10 195463 dinov2 ssl_meta_arch.py:47] OPTIONS -- pretrained weights: loading from /mnt/c/Users/kosta/Downloads/dinov2_vitb14_reg4_pretrain.pth
I20240923 18:10:19 199253 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:10:19 199253 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:10:19 199253 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:10:19 199253 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: /mnt/c/Users/kosta/Downloads/dinov2_vitb14_reg4_pretrain.pth
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 0
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:10:19 199253 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:10:19 199253 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:10:20 199253 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:10:21 199253 dinov2 ssl_meta_arch.py:47] OPTIONS -- pretrained weights: loading from /mnt/c/Users/kosta/Downloads/dinov2_vitb14_reg4_pretrain.pth
I20240923 18:23:32 207975 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:23:32 207975 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:23:32 207975 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:23:32 207975 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: /mnt/c/Users/kosta/Downloads/dinov2_vitb14_reg4_pretrain.pth
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 0
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:23:32 207975 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:23:33 207975 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:23:33 207975 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:23:34 207975 dinov2 ssl_meta_arch.py:47] OPTIONS -- pretrained weights: loading from /mnt/c/Users/kosta/Downloads/dinov2_vitb14_reg4_pretrain.pth
I20240923 18:23:57 208425 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:23:57 208425 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:23:57 208425 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:23:57 208425 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0.4
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 0
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:23:57 208425 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:23:57 208425 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_base network.
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240923 18:23:58 208425 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240923 18:23:58 208425 dinov2 train.py:303] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): DropPath()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): DropPath()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240923 18:23:58 208425 dinov2 param_groups.py:54] chunked fsdp
I20240923 18:23:58 208425 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] blocks.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:23:58 208425 dinov2 param_groups.py:64] else code branch
I20240923 18:23:58 208425 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:23:58 208425 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:23:58 208425 dinov2 train.py:102] Schedulers ready.
I20240923 18:23:58 208425 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240923 18:23:58 208425 dinov2 augmentations.py:34] ###################################
I20240923 18:23:58 208425 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240923 18:23:58 208425 dinov2 augmentations.py:36] global_crops_scale: [0.4, 1.0]
I20240923 18:23:58 208425 dinov2 augmentations.py:37] local_crops_scale: [0.1, 0.4]
I20240923 18:23:58 208425 dinov2 augmentations.py:38] local_crops_number: 10
I20240923 18:23:58 208425 dinov2 augmentations.py:39] global_crops_size: 224
I20240923 18:23:58 208425 dinov2 augmentations.py:40] local_crops_size: 98
I20240923 18:23:58 208425 dinov2 augmentations.py:41] ###################################
I20240923 18:23:58 208425 dinov2 loaders.py:80] using dataset: "MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train"
I20240923 18:23:58 208425 dinov2 loaders.py:89] # of dataset samples: 13,823
I20240923 18:23:58 208425 dinov2 loaders.py:122] sampler: sharded infinite
I20240923 18:23:58 208425 dinov2 loaders.py:204] using PyTorch data loader
I20240923 18:23:58 208425 dinov2 loaders.py:219] infinite data loader
I20240923 18:23:58 208425 dinov2 train.py:217] Starting training from iteration 0
W20240923 18:24:05 208425 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()

W20240923 18:24:05 208425 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()

W20240923 18:24:05 208425 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20240923 18:24:05 208425 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20240923 18:24:05 208425 dinov2 helpers.py:102] Training  [     0/160000]  eta: 13 days, 3:00:18  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8144 (14.8144)  dino_local_crops_loss: 10.2595 (10.2595)  dino_global_crops_loss: 1.0260 (1.0260)  koleo_loss: 0.7114 (0.7114)  ibot_loss: 2.8175 (2.8175)  time: 7.087616  data: 3.928783  max mem: 5226
I20240923 18:24:07 208425 dinov2 helpers.py:102] Training  [    10/160000]  eta: 1 day, 12:17:44  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8064 (14.7452)  dino_local_crops_loss: 10.2595 (10.2563)  dino_global_crops_loss: 1.0260 (1.0256)  koleo_loss: 0.7026 (0.6462)  ibot_loss: 2.8171 (2.8171)  time: 0.816705  data: 0.357318  max mem: 6081
I20240923 18:24:10 208425 dinov2 helpers.py:102] Training  [    20/160000]  eta: 1 day, 0:56:14  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5312 (14.6178)  dino_local_crops_loss: 10.2464 (10.2503)  dino_global_crops_loss: 1.0246 (1.0250)  koleo_loss: 0.4438 (0.5259)  ibot_loss: 2.8167 (2.8166)  time: 0.234840  data: 0.045519  max mem: 6081
I20240923 18:24:14 208425 dinov2 helpers.py:102] Training  [    30/160000]  eta: 22:42:45  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4381 (14.5476)  dino_local_crops_loss: 10.2416 (10.2472)  dino_global_crops_loss: 1.0242 (1.0247)  koleo_loss: 0.3547 (0.4592)  ibot_loss: 2.8162 (2.8165)  time: 0.343063  data: 0.145990  max mem: 6081
I20240923 18:24:20 208425 dinov2 helpers.py:102] Training  [    40/160000]  eta: 23:42:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.3585 (14.4920)  dino_local_crops_loss: 10.2400 (10.2454)  dino_global_crops_loss: 1.0240 (1.0245)  koleo_loss: 0.2793 (0.4061)  ibot_loss: 2.8155 (2.8160)  time: 0.504737  data: 0.288526  max mem: 6081
I20240923 18:27:04 211027 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:27:04 211027 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:27:04 211027 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:27:04 211027 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 0
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:27:04 211027 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:27:04 211027 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_base network.
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240923 18:27:05 211027 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240923 18:27:05 211027 dinov2 train.py:303] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240923 18:27:05 211027 dinov2 param_groups.py:54] chunked fsdp
I20240923 18:27:05 211027 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] blocks.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:27:05 211027 dinov2 param_groups.py:64] else code branch
I20240923 18:27:05 211027 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:27:05 211027 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:27:05 211027 dinov2 train.py:102] Schedulers ready.
I20240923 18:27:05 211027 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240923 18:27:05 211027 dinov2 augmentations.py:34] ###################################
I20240923 18:27:05 211027 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240923 18:27:05 211027 dinov2 augmentations.py:36] global_crops_scale: [0.4, 1.0]
I20240923 18:27:05 211027 dinov2 augmentations.py:37] local_crops_scale: [0.1, 0.4]
I20240923 18:27:05 211027 dinov2 augmentations.py:38] local_crops_number: 10
I20240923 18:27:05 211027 dinov2 augmentations.py:39] global_crops_size: 224
I20240923 18:27:05 211027 dinov2 augmentations.py:40] local_crops_size: 98
I20240923 18:27:05 211027 dinov2 augmentations.py:41] ###################################
I20240923 18:27:05 211027 dinov2 loaders.py:80] using dataset: "MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train"
I20240923 18:27:05 211027 dinov2 loaders.py:89] # of dataset samples: 13,823
I20240923 18:27:05 211027 dinov2 loaders.py:122] sampler: sharded infinite
I20240923 18:27:05 211027 dinov2 loaders.py:204] using PyTorch data loader
I20240923 18:27:05 211027 dinov2 loaders.py:219] infinite data loader
I20240923 18:27:05 211027 dinov2 train.py:217] Starting training from iteration 0
W20240923 18:27:11 211027 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()

W20240923 18:27:11 211027 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()

W20240923 18:27:11 211027 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20240923 18:27:11 211027 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20240923 18:27:11 211027 dinov2 helpers.py:102] Training  [     0/160000]  eta: 10 days, 11:08:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9927 (14.9927)  dino_local_crops_loss: 10.2595 (10.2595)  dino_global_crops_loss: 1.0260 (1.0260)  koleo_loss: 0.8896 (0.8896)  ibot_loss: 2.8175 (2.8175)  time: 5.650539  data: 3.861288  max mem: 7348
I20240923 18:27:13 211027 dinov2 helpers.py:102] Training  [    10/160000]  eta: 1 day, 9:20:22  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9732 (14.9359)  dino_local_crops_loss: 10.2595 (10.2583)  dino_global_crops_loss: 1.0260 (1.0258)  koleo_loss: 0.8721 (0.8347)  ibot_loss: 2.8171 (2.8171)  time: 0.750185  data: 0.375139  max mem: 8176
I20240923 18:27:17 211027 dinov2 helpers.py:102] Training  [    20/160000]  eta: 1 day, 1:47:14  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6853 (14.7760)  dino_local_crops_loss: 10.2490 (10.2520)  dino_global_crops_loss: 1.0249 (1.0252)  koleo_loss: 0.5962 (0.6821)  ibot_loss: 2.8166 (2.8167)  time: 0.326774  data: 0.089603  max mem: 8186
I20240923 18:27:21 211027 dinov2 helpers.py:102] Training  [    30/160000]  eta: 23:10:30  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5550 (14.6915)  dino_local_crops_loss: 10.2421 (10.2485)  dino_global_crops_loss: 1.0242 (1.0248)  koleo_loss: 0.4695 (0.6016)  ibot_loss: 2.8163 (2.8165)  time: 0.395781  data: 0.157146  max mem: 8186
I20240923 18:27:27 211027 dinov2 helpers.py:102] Training  [    40/160000]  eta: 23:26:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4800 (14.6339)  dino_local_crops_loss: 10.2403 (10.2464)  dino_global_crops_loss: 1.0240 (1.0246)  koleo_loss: 0.4011 (0.5470)  ibot_loss: 2.8154 (2.8158)  time: 0.472461  data: 0.237857  max mem: 8186
I20240923 18:27:31 211027 dinov2 helpers.py:102] Training  [    50/160000]  eta: 22:18:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4076 (14.5803)  dino_local_crops_loss: 10.2402 (10.2457)  dino_global_crops_loss: 1.0240 (1.0246)  koleo_loss: 0.3352 (0.4964)  ibot_loss: 2.8114 (2.8136)  time: 0.472000  data: 0.240039  max mem: 8186
I20240923 18:27:35 211027 dinov2 helpers.py:102] Training  [    60/160000]  eta: 21:33:59  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.3042 (14.5296)  dino_local_crops_loss: 10.2480 (10.2468)  dino_global_crops_loss: 1.0248 (1.0247)  koleo_loss: 0.2367 (0.4481)  ibot_loss: 2.7977 (2.8101)  time: 0.398796  data: 0.166991  max mem: 8186
I20240923 18:27:39 211027 dinov2 helpers.py:102] Training  [    70/160000]  eta: 21:04:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2385 (14.4843)  dino_local_crops_loss: 10.2505 (10.2472)  dino_global_crops_loss: 1.0251 (1.0247)  koleo_loss: 0.1764 (0.4054)  ibot_loss: 2.7904 (2.8069)  time: 0.403236  data: 0.167772  max mem: 8186
I20240923 18:27:44 211027 dinov2 helpers.py:102] Training  [    80/160000]  eta: 21:33:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1750 (14.4436)  dino_local_crops_loss: 10.2478 (10.2471)  dino_global_crops_loss: 1.0248 (1.0247)  koleo_loss: 0.1252 (0.3681)  ibot_loss: 2.7840 (2.8038)  time: 0.484787  data: 0.246106  max mem: 8187
I20240923 18:27:49 211027 dinov2 helpers.py:102] Training  [    90/160000]  eta: 21:12:31  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1333 (14.4085)  dino_local_crops_loss: 10.2442 (10.2466)  dino_global_crops_loss: 1.0245 (1.0247)  koleo_loss: 0.0850 (0.3361)  ibot_loss: 2.7802 (2.8012)  time: 0.488862  data: 0.253047  max mem: 8187
I20240923 18:27:53 211027 dinov2 helpers.py:102] Training  [   100/160000]  eta: 20:55:28  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1200 (14.3804)  dino_local_crops_loss: 10.2413 (10.2460)  dino_global_crops_loss: 1.0245 (1.0246)  koleo_loss: 0.0759 (0.3107)  ibot_loss: 2.7802 (2.7991)  time: 0.413699  data: 0.178280  max mem: 8192
I20240923 18:27:57 211027 dinov2 helpers.py:102] Training  [   110/160000]  eta: 20:38:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1134 (14.3557)  dino_local_crops_loss: 10.2389 (10.2450)  dino_global_crops_loss: 1.0238 (1.0245)  koleo_loss: 0.0743 (0.2891)  ibot_loss: 2.7747 (2.7970)  time: 0.407489  data: 0.172008  max mem: 8192
I20240923 18:28:02 211027 dinov2 helpers.py:102] Training  [   120/160000]  eta: 21:01:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1041 (14.3345)  dino_local_crops_loss: 10.2301 (10.2434)  dino_global_crops_loss: 1.0224 (1.0243)  koleo_loss: 0.0698 (0.2713)  ibot_loss: 2.7737 (2.7954)  time: 0.485238  data: 0.252075  max mem: 8192
I20240923 18:28:07 211027 dinov2 helpers.py:102] Training  [   130/160000]  eta: 20:49:38  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0919 (14.3154)  dino_local_crops_loss: 10.2194 (10.2414)  dino_global_crops_loss: 1.0222 (1.0242)  koleo_loss: 0.0698 (0.2559)  ibot_loss: 2.7764 (2.7938)  time: 0.491966  data: 0.259164  max mem: 8192
I20240923 18:28:11 211027 dinov2 helpers.py:102] Training  [   140/160000]  eta: 20:37:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0681 (14.2966)  dino_local_crops_loss: 10.2092 (10.2385)  dino_global_crops_loss: 1.0223 (1.0240)  koleo_loss: 0.0673 (0.2427)  ibot_loss: 2.7637 (2.7913)  time: 0.411356  data: 0.179185  max mem: 8192
I20240923 18:28:15 211027 dinov2 helpers.py:102] Training  [   150/160000]  eta: 20:30:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0509 (14.2808)  dino_local_crops_loss: 10.1995 (10.2361)  dino_global_crops_loss: 1.0204 (1.0238)  koleo_loss: 0.0641 (0.2309)  ibot_loss: 2.7614 (2.7900)  time: 0.413940  data: 0.179534  max mem: 8192
I20240923 18:28:20 211027 dinov2 helpers.py:102] Training  [   160/160000]  eta: 20:39:19  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0476 (14.2665)  dino_local_crops_loss: 10.2018 (10.2334)  dino_global_crops_loss: 1.0212 (1.0236)  koleo_loss: 0.0608 (0.2203)  ibot_loss: 2.7753 (2.7891)  time: 0.469333  data: 0.233510  max mem: 8192
I20240923 18:28:24 211027 dinov2 helpers.py:102] Training  [   170/160000]  eta: 20:35:20  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0366 (14.2519)  dino_local_crops_loss: 10.1890 (10.2302)  dino_global_crops_loss: 1.0192 (1.0233)  koleo_loss: 0.0554 (0.2106)  ibot_loss: 2.7713 (2.7878)  time: 0.479143  data: 0.245302  max mem: 8192
I20240923 18:28:28 211027 dinov2 helpers.py:102] Training  [   180/160000]  eta: 20:25:14  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0233 (14.2399)  dino_local_crops_loss: 10.1842 (10.2281)  dino_global_crops_loss: 1.0193 (1.0232)  koleo_loss: 0.0508 (0.2017)  ibot_loss: 2.7688 (2.7869)  time: 0.417857  data: 0.185571  max mem: 8192
I20240923 18:28:33 211027 dinov2 helpers.py:102] Training  [   190/160000]  eta: 20:18:01  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0206 (14.2272)  dino_local_crops_loss: 10.1812 (10.2254)  dino_global_crops_loss: 1.0193 (1.0229)  koleo_loss: 0.0449 (0.1933)  ibot_loss: 2.7644 (2.7856)  time: 0.402205  data: 0.170571  max mem: 8192
I20240923 18:28:38 211027 dinov2 helpers.py:102] Training  [   200/160000]  eta: 20:28:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9973 (14.2159)  dino_local_crops_loss: 10.1729 (10.2229)  dino_global_crops_loss: 1.0182 (1.0228)  koleo_loss: 0.0401 (0.1857)  ibot_loss: 2.7622 (2.7846)  time: 0.474453  data: 0.241647  max mem: 8192
I20240923 18:28:42 211027 dinov2 helpers.py:102] Training  [   210/160000]  eta: 20:24:13  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9885 (14.2045)  dino_local_crops_loss: 10.1656 (10.2194)  dino_global_crops_loss: 1.0179 (1.0225)  koleo_loss: 0.0401 (0.1787)  ibot_loss: 2.7699 (2.7839)  time: 0.482472  data: 0.249518  max mem: 8192
I20240923 18:28:46 211027 dinov2 helpers.py:102] Training  [   220/160000]  eta: 20:18:14  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9594 (14.1935)  dino_local_crops_loss: 10.1352 (10.2160)  dino_global_crops_loss: 1.0170 (1.0222)  koleo_loss: 0.0372 (0.1722)  ibot_loss: 2.7676 (2.7831)  time: 0.417753  data: 0.184281  max mem: 8192
I20240923 18:29:02 213183 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:29:02 213183 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:29:02 213183 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:29:02 213183 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: dinov2_vitb14_reg
  patch_size: 14
  drop_path_rate: 0
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 10
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:32:29 215416 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240923 18:32:29 215416 dinov2 config.py:60] config_file: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/configs/train/mineral_vitb14.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output']
output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
I20240923 18:32:29 215416 dinov2 config.py:26] sqrt scaling learning rate; base: 0.0003, new: 3.75e-05
I20240923 18:32:29 215416 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 16
  dataset_path: MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train
  output_dir: /home/kosta/code/Mineral-Vision-Model-Bit-Space-/prototyping/unsupervised/BitScope/models/dinov2/dinov2/train/output
  saveckp_freq: 20
  seed: 0
  num_workers: 8
  OFFICIAL_EPOCH_LENGTH: 800
  cache_dataset: true
  centering: sinkhorn_knopp
student:
  arch: vit_base
  patch_size: 14
  drop_path_rate: 0
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 0
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 200
  weight_decay: 0.04
  weight_decay_end: 0.05
  base_lr: 0.0003
  lr: 3.75e-05
  warmup_epochs: 10
  min_lr: 1.0e-07
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
  scheduler: cosine
crops:
  global_crops_scale:
  - 0.4
  - 1.0
  local_crops_number: 10
  local_crops_scale:
  - 0.1
  - 0.4
  global_crops_size: 224
  local_crops_size: 98
evaluation:
  eval_period_iterations: 6250

I20240923 18:32:29 215416 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:32:29 215416 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 768
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_base network.
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240923 18:32:30 215416 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240923 18:32:30 215416 dinov2 train.py:304] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0-11): 12 x NestedTensorBlock(
            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (attn): MemEffAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (ls1): LayerScale()
            (drop_path1): Identity()
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (ls2): LayerScale()
            (drop_path2): Identity()
          )
        )
        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=768, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240923 18:32:30 215416 dinov2 param_groups.py:54] chunked fsdp
I20240923 18:32:30 215416 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] blocks.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:32:30 215416 dinov2 param_groups.py:64] else code branch
I20240923 18:32:30 215416 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240923 18:32:30 215416 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240923 18:32:30 215416 dinov2 train.py:102] Schedulers ready.
I20240923 18:32:30 215416 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240923 18:32:30 215416 dinov2 augmentations.py:34] ###################################
I20240923 18:32:30 215416 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240923 18:32:30 215416 dinov2 augmentations.py:36] global_crops_scale: [0.4, 1.0]
I20240923 18:32:30 215416 dinov2 augmentations.py:37] local_crops_scale: [0.1, 0.4]
I20240923 18:32:30 215416 dinov2 augmentations.py:38] local_crops_number: 10
I20240923 18:32:30 215416 dinov2 augmentations.py:39] global_crops_size: 224
I20240923 18:32:30 215416 dinov2 augmentations.py:40] local_crops_size: 98
I20240923 18:32:30 215416 dinov2 augmentations.py:41] ###################################
I20240923 18:32:30 215416 dinov2 loaders.py:80] using dataset: "MineralDataset:root=/mnt/e/MineralDataset/dataset:split=train"
I20240923 18:32:30 215416 dinov2 loaders.py:89] # of dataset samples: 13,823
I20240923 18:32:30 215416 dinov2 loaders.py:122] sampler: sharded infinite
I20240923 18:32:30 215416 dinov2 loaders.py:204] using PyTorch data loader
I20240923 18:32:30 215416 dinov2 loaders.py:219] infinite data loader
I20240923 18:32:30 215416 dinov2 train.py:218] Starting training from iteration 0
W20240923 18:32:36 215416 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()

W20240923 18:32:36 215416 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.value.storage().data_ptr()

W20240923 18:32:36 215416 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:46: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage_data_ptr = tensors[0].storage().data_ptr()

W20240923 18:32:36 215416 py.warnings warnings.py:109] /home/kosta/anaconda3/envs/dinov2/lib/python3.9/site-packages/xformers/ops/unbind.py:48: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  if x.storage().data_ptr() != storage_data_ptr:

I20240923 18:32:36 215416 dinov2 helpers.py:102] Training  [     0/160000]  eta: 10 days, 20:23:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9927 (14.9927)  dino_local_crops_loss: 10.2595 (10.2595)  dino_global_crops_loss: 1.0260 (1.0260)  koleo_loss: 0.8896 (0.8896)  ibot_loss: 2.8175 (2.8175)  time: 5.858877  data: 3.886360  max mem: 7348
I20240923 18:32:38 215416 dinov2 helpers.py:102] Training  [    10/160000]  eta: 1 day, 8:59:48  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9829 (14.9733)  dino_local_crops_loss: 10.2595 (10.2595)  dino_global_crops_loss: 1.0260 (1.0260)  koleo_loss: 0.8799 (0.8707)  ibot_loss: 2.8171 (2.8171)  time: 0.742475  data: 0.359003  max mem: 8176
I20240923 18:32:42 215416 dinov2 helpers.py:102] Training  [    20/160000]  eta: 1 day, 1:50:51  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9689 (14.9690)  dino_local_crops_loss: 10.2595 (10.2595)  dino_global_crops_loss: 1.0260 (1.0260)  koleo_loss: 0.8672 (0.8667)  ibot_loss: 2.8169 (2.8168)  time: 0.317784  data: 0.088999  max mem: 8186
I20240923 18:32:46 215416 dinov2 helpers.py:102] Training  [    30/160000]  eta: 23:11:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9581 (14.9638)  dino_local_crops_loss: 10.2595 (10.2595)  dino_global_crops_loss: 1.0260 (1.0260)  koleo_loss: 0.8564 (0.8614)  ibot_loss: 2.8169 (2.8169)  time: 0.400626  data: 0.167697  max mem: 8186
I20240923 18:32:52 215416 dinov2 helpers.py:102] Training  [    40/160000]  eta: 23:48:48  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9508 (14.9576)  dino_local_crops_loss: 10.2594 (10.2595)  dino_global_crops_loss: 1.0259 (1.0259)  koleo_loss: 0.8477 (0.8553)  ibot_loss: 2.8170 (2.8169)  time: 0.487943  data: 0.255276  max mem: 8186
I20240923 18:32:56 215416 dinov2 helpers.py:102] Training  [    50/160000]  eta: 22:45:25  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9445 (14.9541)  dino_local_crops_loss: 10.2589 (10.2593)  dino_global_crops_loss: 1.0259 (1.0259)  koleo_loss: 0.8428 (0.8519)  ibot_loss: 2.8168 (2.8169)  time: 0.497112  data: 0.263936  max mem: 8186
I20240923 18:33:00 215416 dinov2 helpers.py:102] Training  [    60/160000]  eta: 21:59:01  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.9381 (14.9491)  dino_local_crops_loss: 10.2586 (10.2592)  dino_global_crops_loss: 1.0259 (1.0259)  koleo_loss: 0.8359 (0.8472)  ibot_loss: 2.8168 (2.8169)  time: 0.410533  data: 0.176935  max mem: 8186
I20240923 18:33:05 215416 dinov2 helpers.py:102] Training  [    70/160000]  eta: 21:26:14  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8956 (14.9410)  dino_local_crops_loss: 10.2584 (10.2590)  dino_global_crops_loss: 1.0258 (1.0259)  koleo_loss: 0.7944 (0.8392)  ibot_loss: 2.8172 (2.8169)  time: 0.406959  data: 0.171455  max mem: 8186
I20240923 18:33:10 215416 dinov2 helpers.py:102] Training  [    80/160000]  eta: 21:49:16  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8886 (14.9346)  dino_local_crops_loss: 10.2579 (10.2589)  dino_global_crops_loss: 1.0258 (1.0259)  koleo_loss: 0.7891 (0.8330)  ibot_loss: 2.8171 (2.8169)  time: 0.480249  data: 0.245008  max mem: 8187
I20240923 18:33:14 215416 dinov2 helpers.py:102] Training  [    90/160000]  eta: 21:30:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8794 (14.9273)  dino_local_crops_loss: 10.2576 (10.2587)  dino_global_crops_loss: 1.0258 (1.0259)  koleo_loss: 0.7788 (0.8258)  ibot_loss: 2.8167 (2.8169)  time: 0.490826  data: 0.256070  max mem: 8187
I20240923 18:33:18 215416 dinov2 helpers.py:102] Training  [   100/160000]  eta: 21:10:18  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8555 (14.9194)  dino_local_crops_loss: 10.2568 (10.2585)  dino_global_crops_loss: 1.0257 (1.0258)  koleo_loss: 0.7563 (0.8182)  ibot_loss: 2.8166 (2.8169)  time: 0.417700  data: 0.178241  max mem: 8192
I20240923 18:33:23 215416 dinov2 helpers.py:102] Training  [   110/160000]  eta: 20:54:27  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8432 (14.9123)  dino_local_crops_loss: 10.2561 (10.2582)  dino_global_crops_loss: 1.0256 (1.0258)  koleo_loss: 0.7441 (0.8113)  ibot_loss: 2.8169 (2.8169)  time: 0.408755  data: 0.167898  max mem: 8192
I20240923 18:33:28 215416 dinov2 helpers.py:102] Training  [   120/160000]  eta: 21:12:10  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8253 (14.9040)  dino_local_crops_loss: 10.2556 (10.2580)  dino_global_crops_loss: 1.0256 (1.0258)  koleo_loss: 0.7266 (0.8033)  ibot_loss: 2.8171 (2.8169)  time: 0.481268  data: 0.242490  max mem: 8192
I20240923 18:33:32 215416 dinov2 helpers.py:102] Training  [   130/160000]  eta: 21:02:23  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.8037 (14.8951)  dino_local_crops_loss: 10.2549 (10.2577)  dino_global_crops_loss: 1.0255 (1.0258)  koleo_loss: 0.7065 (0.7947)  ibot_loss: 2.8170 (2.8169)  time: 0.490626  data: 0.251812  max mem: 8192
I20240923 18:33:36 215416 dinov2 helpers.py:102] Training  [   140/160000]  eta: 20:51:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.7704 (14.8852)  dino_local_crops_loss: 10.2541 (10.2574)  dino_global_crops_loss: 1.0254 (1.0257)  koleo_loss: 0.6743 (0.7851)  ibot_loss: 2.8167 (2.8169)  time: 0.422301  data: 0.181860  max mem: 8192
I20240923 18:33:41 215416 dinov2 helpers.py:102] Training  [   150/160000]  eta: 20:40:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.7669 (14.8778)  dino_local_crops_loss: 10.2532 (10.2572)  dino_global_crops_loss: 1.0253 (1.0257)  koleo_loss: 0.6709 (0.7781)  ibot_loss: 2.8167 (2.8169)  time: 0.410939  data: 0.172863  max mem: 8192
I20240923 18:33:46 215416 dinov2 helpers.py:102] Training  [   160/160000]  eta: 20:58:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.7661 (14.8697)  dino_local_crops_loss: 10.2527 (10.2568)  dino_global_crops_loss: 1.0253 (1.0257)  koleo_loss: 0.6709 (0.7703)  ibot_loss: 2.8167 (2.8169)  time: 0.492725  data: 0.256078  max mem: 8192
I20240923 18:33:51 215416 dinov2 helpers.py:102] Training  [   170/160000]  eta: 20:50:12  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.7370 (14.8617)  dino_local_crops_loss: 10.2518 (10.2565)  dino_global_crops_loss: 1.0252 (1.0257)  koleo_loss: 0.6431 (0.7627)  ibot_loss: 2.8168 (2.8169)  time: 0.498566  data: 0.261988  max mem: 8192
I20240923 18:33:55 215416 dinov2 helpers.py:102] Training  [   180/160000]  eta: 20:43:57  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.7189 (14.8535)  dino_local_crops_loss: 10.2509 (10.2562)  dino_global_crops_loss: 1.0251 (1.0256)  koleo_loss: 0.6260 (0.7548)  ibot_loss: 2.8169 (2.8169)  time: 0.423016  data: 0.186819  max mem: 8192
I20240923 18:33:59 215416 dinov2 helpers.py:102] Training  [   190/160000]  eta: 20:40:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.7016 (14.8454)  dino_local_crops_loss: 10.2500 (10.2558)  dino_global_crops_loss: 1.0250 (1.0256)  koleo_loss: 0.6084 (0.7471)  ibot_loss: 2.8166 (2.8169)  time: 0.433950  data: 0.188781  max mem: 8192
I20240923 18:34:05 215416 dinov2 helpers.py:102] Training  [   200/160000]  eta: 20:58:54  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6896 (14.8374)  dino_local_crops_loss: 10.2491 (10.2555)  dino_global_crops_loss: 1.0249 (1.0255)  koleo_loss: 0.5977 (0.7396)  ibot_loss: 2.8169 (2.8169)  time: 0.523992  data: 0.272881  max mem: 8192
I20240923 18:34:09 215416 dinov2 helpers.py:102] Training  [   210/160000]  eta: 20:49:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6763 (14.8295)  dino_local_crops_loss: 10.2482 (10.2551)  dino_global_crops_loss: 1.0248 (1.0255)  koleo_loss: 0.5859 (0.7320)  ibot_loss: 2.8169 (2.8168)  time: 0.502565  data: 0.260257  max mem: 8192
I20240923 18:34:13 215416 dinov2 helpers.py:102] Training  [   220/160000]  eta: 20:41:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6604 (14.8212)  dino_local_crops_loss: 10.2474 (10.2548)  dino_global_crops_loss: 1.0247 (1.0255)  koleo_loss: 0.5718 (0.7241)  ibot_loss: 2.8168 (2.8168)  time: 0.401263  data: 0.165777  max mem: 8192
I20240923 18:34:18 215416 dinov2 helpers.py:102] Training  [   230/160000]  eta: 20:37:16  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6468 (14.8137)  dino_local_crops_loss: 10.2466 (10.2544)  dino_global_crops_loss: 1.0247 (1.0254)  koleo_loss: 0.5601 (0.7170)  ibot_loss: 2.8166 (2.8168)  time: 0.417348  data: 0.177660  max mem: 8192
I20240923 18:34:24 215416 dinov2 helpers.py:102] Training  [   240/160000]  eta: 20:53:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6468 (14.8064)  dino_local_crops_loss: 10.2457 (10.2540)  dino_global_crops_loss: 1.0246 (1.0254)  koleo_loss: 0.5601 (0.7102)  ibot_loss: 2.8162 (2.8168)  time: 0.518950  data: 0.272921  max mem: 8192
I20240923 18:34:28 215416 dinov2 helpers.py:102] Training  [   250/160000]  eta: 20:44:05  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6420 (14.7991)  dino_local_crops_loss: 10.2450 (10.2536)  dino_global_crops_loss: 1.0245 (1.0254)  koleo_loss: 0.5566 (0.7033)  ibot_loss: 2.8162 (2.8168)  time: 0.497509  data: 0.254474  max mem: 8192
I20240923 18:34:32 215416 dinov2 helpers.py:102] Training  [   260/160000]  eta: 20:37:48  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6074 (14.7916)  dino_local_crops_loss: 10.2442 (10.2533)  dino_global_crops_loss: 1.0244 (1.0253)  koleo_loss: 0.5220 (0.6962)  ibot_loss: 2.8164 (2.8168)  time: 0.396754  data: 0.159442  max mem: 8192
I20240923 18:34:36 215416 dinov2 helpers.py:102] Training  [   270/160000]  eta: 20:31:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.6035 (14.7845)  dino_local_crops_loss: 10.2437 (10.2529)  dino_global_crops_loss: 1.0244 (1.0253)  koleo_loss: 0.5181 (0.6895)  ibot_loss: 2.8168 (2.8168)  time: 0.403297  data: 0.165554  max mem: 8192
I20240923 18:34:42 215416 dinov2 helpers.py:102] Training  [   280/160000]  eta: 20:43:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5942 (14.7777)  dino_local_crops_loss: 10.2430 (10.2525)  dino_global_crops_loss: 1.0243 (1.0253)  koleo_loss: 0.5098 (0.6831)  ibot_loss: 2.8168 (2.8168)  time: 0.496693  data: 0.252906  max mem: 8192
I20240923 18:34:46 215416 dinov2 helpers.py:102] Training  [   290/160000]  eta: 20:36:59  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5870 (14.7710)  dino_local_crops_loss: 10.2425 (10.2522)  dino_global_crops_loss: 1.0242 (1.0252)  koleo_loss: 0.5029 (0.6768)  ibot_loss: 2.8168 (2.8168)  time: 0.494144  data: 0.254145  max mem: 8192
I20240923 18:34:50 215416 dinov2 helpers.py:102] Training  [   300/160000]  eta: 20:32:30  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5718 (14.7644)  dino_local_crops_loss: 10.2420 (10.2518)  dino_global_crops_loss: 1.0242 (1.0252)  koleo_loss: 0.4883 (0.6706)  ibot_loss: 2.8169 (2.8168)  time: 0.404933  data: 0.171090  max mem: 8192
I20240923 18:34:54 215416 dinov2 helpers.py:102] Training  [   310/160000]  eta: 20:28:22  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5802 (14.7591)  dino_local_crops_loss: 10.2415 (10.2515)  dino_global_crops_loss: 1.0242 (1.0252)  koleo_loss: 0.4976 (0.6657)  ibot_loss: 2.8165 (2.8168)  time: 0.415304  data: 0.172897  max mem: 8192
I20240923 18:35:00 215416 dinov2 helpers.py:102] Training  [   320/160000]  eta: 20:40:15  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5952 (14.7541)  dino_local_crops_loss: 10.2412 (10.2512)  dino_global_crops_loss: 1.0241 (1.0251)  koleo_loss: 0.5146 (0.6610)  ibot_loss: 2.8162 (2.8167)  time: 0.510764  data: 0.261308  max mem: 8192
I20240923 18:35:04 215416 dinov2 helpers.py:102] Training  [   330/160000]  eta: 20:33:50  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5813 (14.7481)  dino_local_crops_loss: 10.2409 (10.2509)  dino_global_crops_loss: 1.0241 (1.0251)  koleo_loss: 0.4993 (0.6554)  ibot_loss: 2.8163 (2.8167)  time: 0.496421  data: 0.254349  max mem: 8192
I20240923 18:35:08 215416 dinov2 helpers.py:102] Training  [   340/160000]  eta: 20:29:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5459 (14.7421)  dino_local_crops_loss: 10.2405 (10.2506)  dino_global_crops_loss: 1.0241 (1.0251)  koleo_loss: 0.4648 (0.6497)  ibot_loss: 2.8164 (2.8167)  time: 0.395105  data: 0.160859  max mem: 8192
I20240923 18:35:12 215416 dinov2 helpers.py:102] Training  [   350/160000]  eta: 20:26:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5482 (14.7367)  dino_local_crops_loss: 10.2403 (10.2503)  dino_global_crops_loss: 1.0240 (1.0250)  koleo_loss: 0.4675 (0.6447)  ibot_loss: 2.8165 (2.8167)  time: 0.414077  data: 0.173393  max mem: 8192
I20240923 18:35:18 215416 dinov2 helpers.py:102] Training  [   360/160000]  eta: 20:36:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5528 (14.7319)  dino_local_crops_loss: 10.2400 (10.2500)  dino_global_crops_loss: 1.0240 (1.0250)  koleo_loss: 0.4722 (0.6402)  ibot_loss: 2.8166 (2.8167)  time: 0.512908  data: 0.263074  max mem: 8192
I20240923 18:35:22 215416 dinov2 helpers.py:102] Training  [   370/160000]  eta: 20:32:19  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5505 (14.7265)  dino_local_crops_loss: 10.2397 (10.2497)  dino_global_crops_loss: 1.0240 (1.0250)  koleo_loss: 0.4702 (0.6351)  ibot_loss: 2.8166 (2.8167)  time: 0.504790  data: 0.259338  max mem: 8192
I20240923 18:35:26 215416 dinov2 helpers.py:102] Training  [   380/160000]  eta: 20:27:23  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5226 (14.7211)  dino_local_crops_loss: 10.2396 (10.2494)  dino_global_crops_loss: 1.0240 (1.0249)  koleo_loss: 0.4419 (0.6300)  ibot_loss: 2.8161 (2.8167)  time: 0.401218  data: 0.166548  max mem: 8192
I20240923 18:35:30 215416 dinov2 helpers.py:102] Training  [   390/160000]  eta: 20:23:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5204 (14.7162)  dino_local_crops_loss: 10.2394 (10.2492)  dino_global_crops_loss: 1.0239 (1.0249)  koleo_loss: 0.4402 (0.6254)  ibot_loss: 2.8165 (2.8167)  time: 0.401901  data: 0.166618  max mem: 8192
I20240923 18:35:36 215416 dinov2 helpers.py:102] Training  [   400/160000]  eta: 20:31:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5424 (14.7120)  dino_local_crops_loss: 10.2391 (10.2489)  dino_global_crops_loss: 1.0239 (1.0249)  koleo_loss: 0.4629 (0.6215)  ibot_loss: 2.8166 (2.8167)  time: 0.493875  data: 0.257925  max mem: 8192
I20240923 18:35:40 215416 dinov2 helpers.py:102] Training  [   410/160000]  eta: 20:27:41  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5383 (14.7075)  dino_local_crops_loss: 10.2389 (10.2487)  dino_global_crops_loss: 1.0239 (1.0249)  koleo_loss: 0.4595 (0.6173)  ibot_loss: 2.8162 (2.8167)  time: 0.491096  data: 0.256318  max mem: 8192
I20240923 18:35:44 215416 dinov2 helpers.py:102] Training  [   420/160000]  eta: 20:23:30  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5260 (14.7035)  dino_local_crops_loss: 10.2388 (10.2484)  dino_global_crops_loss: 1.0239 (1.0248)  koleo_loss: 0.4478 (0.6135)  ibot_loss: 2.8161 (2.8167)  time: 0.400605  data: 0.164842  max mem: 8192
I20240923 18:35:48 215416 dinov2 helpers.py:102] Training  [   430/160000]  eta: 20:21:29  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5235 (14.6990)  dino_local_crops_loss: 10.2387 (10.2482)  dino_global_crops_loss: 1.0239 (1.0248)  koleo_loss: 0.4434 (0.6093)  ibot_loss: 2.8161 (2.8166)  time: 0.412670  data: 0.172228  max mem: 8192
I20240923 18:35:54 215416 dinov2 helpers.py:102] Training  [   440/160000]  eta: 20:28:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5045 (14.6947)  dino_local_crops_loss: 10.2385 (10.2480)  dino_global_crops_loss: 1.0239 (1.0248)  koleo_loss: 0.4272 (0.6053)  ibot_loss: 2.8160 (2.8166)  time: 0.501873  data: 0.261617  max mem: 8192
I20240923 18:35:58 215416 dinov2 helpers.py:102] Training  [   450/160000]  eta: 20:24:57  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5169 (14.6907)  dino_local_crops_loss: 10.2383 (10.2478)  dino_global_crops_loss: 1.0238 (1.0248)  koleo_loss: 0.4390 (0.6016)  ibot_loss: 2.8158 (2.8166)  time: 0.489950  data: 0.254840  max mem: 8192
I20240923 18:36:02 215416 dinov2 helpers.py:102] Training  [   460/160000]  eta: 20:21:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.5056 (14.6866)  dino_local_crops_loss: 10.2381 (10.2476)  dino_global_crops_loss: 1.0238 (1.0248)  koleo_loss: 0.4304 (0.5977)  ibot_loss: 2.8155 (2.8166)  time: 0.406155  data: 0.168874  max mem: 8193
I20240923 18:36:07 215416 dinov2 helpers.py:102] Training  [   470/160000]  eta: 20:21:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4978 (14.6825)  dino_local_crops_loss: 10.2377 (10.2473)  dino_global_crops_loss: 1.0238 (1.0247)  koleo_loss: 0.4199 (0.5939)  ibot_loss: 2.8154 (2.8166)  time: 0.428225  data: 0.180824  max mem: 8193
I20240923 18:36:12 215416 dinov2 helpers.py:102] Training  [   480/160000]  eta: 20:26:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4849 (14.6782)  dino_local_crops_loss: 10.2376 (10.2471)  dino_global_crops_loss: 1.0238 (1.0247)  koleo_loss: 0.4082 (0.5899)  ibot_loss: 2.8149 (2.8165)  time: 0.505857  data: 0.256561  max mem: 8193
I20240923 18:36:16 215416 dinov2 helpers.py:102] Training  [   490/160000]  eta: 20:22:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4762 (14.6740)  dino_local_crops_loss: 10.2370 (10.2469)  dino_global_crops_loss: 1.0238 (1.0247)  koleo_loss: 0.3999 (0.5859)  ibot_loss: 2.8149 (2.8165)  time: 0.477059  data: 0.237372  max mem: 8193
I20240923 18:36:20 215416 dinov2 helpers.py:102] Training  [   500/160000]  eta: 20:20:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4521 (14.6694)  dino_local_crops_loss: 10.2359 (10.2467)  dino_global_crops_loss: 1.0236 (1.0247)  koleo_loss: 0.3782 (0.5816)  ibot_loss: 2.8146 (2.8164)  time: 0.405176  data: 0.165177  max mem: 8193
I20240923 18:36:24 215416 dinov2 helpers.py:102] Training  [   510/160000]  eta: 20:17:38  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4402 (14.6648)  dino_local_crops_loss: 10.2349 (10.2464)  dino_global_crops_loss: 1.0235 (1.0247)  koleo_loss: 0.3657 (0.5773)  ibot_loss: 2.8145 (2.8164)  time: 0.410753  data: 0.169525  max mem: 8193
I20240923 18:36:30 215416 dinov2 helpers.py:102] Training  [   520/160000]  eta: 20:24:07  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4239 (14.6601)  dino_local_crops_loss: 10.2341 (10.2462)  dino_global_crops_loss: 1.0235 (1.0246)  koleo_loss: 0.3525 (0.5729)  ibot_loss: 2.8137 (2.8163)  time: 0.494653  data: 0.249768  max mem: 8193
I20240923 18:36:34 215416 dinov2 helpers.py:102] Training  [   530/160000]  eta: 20:21:10  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.4028 (14.6549)  dino_local_crops_loss: 10.2330 (10.2459)  dino_global_crops_loss: 1.0235 (1.0246)  koleo_loss: 0.3320 (0.5680)  ibot_loss: 2.8137 (2.8163)  time: 0.494974  data: 0.250692  max mem: 8193
I20240923 18:36:38 215416 dinov2 helpers.py:102] Training  [   540/160000]  eta: 20:18:20  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.3720 (14.6495)  dino_local_crops_loss: 10.2328 (10.2457)  dino_global_crops_loss: 1.0233 (1.0246)  koleo_loss: 0.3032 (0.5630)  ibot_loss: 2.8136 (2.8162)  time: 0.403103  data: 0.167577  max mem: 8193
I20240923 18:36:43 215416 dinov2 helpers.py:102] Training  [   550/160000]  eta: 20:16:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.3465 (14.6435)  dino_local_crops_loss: 10.2300 (10.2454)  dino_global_crops_loss: 1.0231 (1.0245)  koleo_loss: 0.2727 (0.5574)  ibot_loss: 2.8132 (2.8162)  time: 0.412937  data: 0.175309  max mem: 8193
I20240923 18:36:48 215416 dinov2 helpers.py:102] Training  [   560/160000]  eta: 20:21:23  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.3058 (14.6373)  dino_local_crops_loss: 10.2252 (10.2450)  dino_global_crops_loss: 1.0228 (1.0245)  koleo_loss: 0.2455 (0.5517)  ibot_loss: 2.8129 (2.8161)  time: 0.492335  data: 0.252515  max mem: 8193
I20240923 18:36:52 215416 dinov2 helpers.py:102] Training  [   570/160000]  eta: 20:18:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2925 (14.6312)  dino_local_crops_loss: 10.2239 (10.2447)  dino_global_crops_loss: 1.0231 (1.0245)  koleo_loss: 0.2344 (0.5460)  ibot_loss: 2.8125 (2.8161)  time: 0.484968  data: 0.248066  max mem: 8193
I20240923 18:36:56 215416 dinov2 helpers.py:102] Training  [   580/160000]  eta: 20:16:29  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2838 (14.6251)  dino_local_crops_loss: 10.2267 (10.2443)  dino_global_crops_loss: 1.0233 (1.0245)  koleo_loss: 0.2152 (0.5403)  ibot_loss: 2.8118 (2.8160)  time: 0.407755  data: 0.171165  max mem: 8193
I20240923 18:37:00 215416 dinov2 helpers.py:102] Training  [   590/160000]  eta: 20:14:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2614 (14.6188)  dino_local_crops_loss: 10.2203 (10.2439)  dino_global_crops_loss: 1.0223 (1.0244)  koleo_loss: 0.2063 (0.5346)  ibot_loss: 2.8123 (2.8159)  time: 0.406112  data: 0.167648  max mem: 8193
I20240923 18:37:06 215416 dinov2 helpers.py:102] Training  [   600/160000]  eta: 20:19:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2399 (14.6123)  dino_local_crops_loss: 10.2132 (10.2432)  dino_global_crops_loss: 1.0210 (1.0244)  koleo_loss: 0.1949 (0.5289)  ibot_loss: 2.8122 (2.8159)  time: 0.497232  data: 0.255976  max mem: 8193
I20240923 18:37:11 215416 dinov2 helpers.py:102] Training  [   610/160000]  eta: 20:18:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2232 (14.6060)  dino_local_crops_loss: 10.2058 (10.2427)  dino_global_crops_loss: 1.0206 (1.0243)  koleo_loss: 0.1823 (0.5231)  ibot_loss: 2.8124 (2.8158)  time: 0.508959  data: 0.262877  max mem: 8193
I20240923 18:37:14 215416 dinov2 helpers.py:102] Training  [   620/160000]  eta: 20:15:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2184 (14.5996)  dino_local_crops_loss: 10.2053 (10.2419)  dino_global_crops_loss: 1.0213 (1.0243)  koleo_loss: 0.1799 (0.5177)  ibot_loss: 2.8122 (2.8158)  time: 0.409253  data: 0.167334  max mem: 8193
I20240923 18:37:19 215416 dinov2 helpers.py:102] Training  [   630/160000]  eta: 20:13:19  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.2025 (14.5932)  dino_local_crops_loss: 10.1988 (10.2412)  dino_global_crops_loss: 1.0196 (1.0242)  koleo_loss: 0.1648 (0.5121)  ibot_loss: 2.8116 (2.8157)  time: 0.400047  data: 0.165390  max mem: 8193
I20240923 18:37:24 215416 dinov2 helpers.py:102] Training  [   640/160000]  eta: 20:18:35  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1785 (14.5866)  dino_local_crops_loss: 10.1883 (10.2401)  dino_global_crops_loss: 1.0194 (1.0241)  koleo_loss: 0.1637 (0.5067)  ibot_loss: 2.8118 (2.8156)  time: 0.497952  data: 0.260768  max mem: 8193
I20240923 18:37:29 215416 dinov2 helpers.py:102] Training  [   650/160000]  eta: 20:17:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1716 (14.5803)  dino_local_crops_loss: 10.1883 (10.2394)  dino_global_crops_loss: 1.0202 (1.0241)  koleo_loss: 0.1488 (0.5012)  ibot_loss: 2.8122 (2.8156)  time: 0.505548  data: 0.262062  max mem: 8193
I20240923 18:37:33 215416 dinov2 helpers.py:102] Training  [   660/160000]  eta: 20:14:15  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1645 (14.5738)  dino_local_crops_loss: 10.1748 (10.2384)  dino_global_crops_loss: 1.0200 (1.0240)  koleo_loss: 0.1475 (0.4959)  ibot_loss: 2.8122 (2.8155)  time: 0.406626  data: 0.166817  max mem: 8193
I20240923 18:37:37 215416 dinov2 helpers.py:102] Training  [   670/160000]  eta: 20:12:25  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1458 (14.5674)  dino_local_crops_loss: 10.1649 (10.2374)  dino_global_crops_loss: 1.0177 (1.0239)  koleo_loss: 0.1404 (0.4906)  ibot_loss: 2.8118 (2.8155)  time: 0.400548  data: 0.165039  max mem: 8193
I20240923 18:37:43 215416 dinov2 helpers.py:102] Training  [   680/160000]  eta: 20:17:33  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1351 (14.5609)  dino_local_crops_loss: 10.1621 (10.2363)  dino_global_crops_loss: 1.0170 (1.0238)  koleo_loss: 0.1396 (0.4854)  ibot_loss: 2.8119 (2.8154)  time: 0.501657  data: 0.265652  max mem: 8193
I20240923 18:37:47 215416 dinov2 helpers.py:102] Training  [   690/160000]  eta: 20:16:04  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1163 (14.5545)  dino_local_crops_loss: 10.1570 (10.2352)  dino_global_crops_loss: 1.0165 (1.0237)  koleo_loss: 0.1345 (0.4803)  ibot_loss: 2.8114 (2.8153)  time: 0.506180  data: 0.266652  max mem: 8193
I20240923 18:37:51 215416 dinov2 helpers.py:102] Training  [   700/160000]  eta: 20:14:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1242 (14.5485)  dino_local_crops_loss: 10.1596 (10.2343)  dino_global_crops_loss: 1.0176 (1.0236)  koleo_loss: 0.1227 (0.4752)  ibot_loss: 2.8115 (2.8153)  time: 0.415591  data: 0.174475  max mem: 8193
I20240923 18:37:55 215416 dinov2 helpers.py:102] Training  [   710/160000]  eta: 20:11:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1198 (14.5421)  dino_local_crops_loss: 10.1606 (10.2330)  dino_global_crops_loss: 1.0162 (1.0235)  koleo_loss: 0.1252 (0.4704)  ibot_loss: 2.8115 (2.8152)  time: 0.403154  data: 0.167648  max mem: 8193
I20240923 18:38:01 215416 dinov2 helpers.py:102] Training  [   720/160000]  eta: 20:17:14  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1097 (14.5363)  dino_local_crops_loss: 10.1562 (10.2321)  dino_global_crops_loss: 1.0165 (1.0234)  koleo_loss: 0.1259 (0.4656)  ibot_loss: 2.8104 (2.8152)  time: 0.501207  data: 0.257591  max mem: 8193
I20240923 18:38:05 215416 dinov2 helpers.py:102] Training  [   730/160000]  eta: 20:14:27  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.1097 (14.5301)  dino_local_crops_loss: 10.1529 (10.2309)  dino_global_crops_loss: 1.0167 (1.0233)  koleo_loss: 0.1152 (0.4607)  ibot_loss: 2.8104 (2.8151)  time: 0.494642  data: 0.249120  max mem: 8193
I20240923 18:38:09 215416 dinov2 helpers.py:102] Training  [   740/160000]  eta: 20:12:26  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0803 (14.5239)  dino_local_crops_loss: 10.1388 (10.2296)  dino_global_crops_loss: 1.0143 (1.0232)  koleo_loss: 0.1090 (0.4560)  ibot_loss: 2.8106 (2.8150)  time: 0.393568  data: 0.157066  max mem: 8193
I20240923 18:38:13 215416 dinov2 helpers.py:102] Training  [   750/160000]  eta: 20:10:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0803 (14.5182)  dino_local_crops_loss: 10.1442 (10.2286)  dino_global_crops_loss: 1.0163 (1.0231)  koleo_loss: 0.1090 (0.4514)  ibot_loss: 2.8108 (2.8150)  time: 0.401709  data: 0.167759  max mem: 8193
I20240923 18:38:19 215416 dinov2 helpers.py:102] Training  [   760/160000]  eta: 20:15:01  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0802 (14.5125)  dino_local_crops_loss: 10.1513 (10.2276)  dino_global_crops_loss: 1.0179 (1.0230)  koleo_loss: 0.1090 (0.4469)  ibot_loss: 2.8108 (2.8149)  time: 0.496184  data: 0.257770  max mem: 8193
I20240923 18:38:23 215416 dinov2 helpers.py:102] Training  [   770/160000]  eta: 20:12:43  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0730 (14.5066)  dino_local_crops_loss: 10.1481 (10.2263)  dino_global_crops_loss: 1.0155 (1.0229)  koleo_loss: 0.1044 (0.4425)  ibot_loss: 2.8101 (2.8149)  time: 0.492703  data: 0.253416  max mem: 8193
I20240923 18:38:27 215416 dinov2 helpers.py:102] Training  [   780/160000]  eta: 20:11:44  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0442 (14.5006)  dino_local_crops_loss: 10.1271 (10.2250)  dino_global_crops_loss: 1.0095 (1.0227)  koleo_loss: 0.0934 (0.4380)  ibot_loss: 2.8106 (2.8148)  time: 0.411612  data: 0.167823  max mem: 8193
I20240923 18:38:31 215416 dinov2 helpers.py:102] Training  [   790/160000]  eta: 20:09:33  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0502 (14.4950)  dino_local_crops_loss: 10.1325 (10.2239)  dino_global_crops_loss: 1.0104 (1.0226)  koleo_loss: 0.0908 (0.4337)  ibot_loss: 2.8105 (2.8148)  time: 0.412073  data: 0.167865  max mem: 8193
I20240923 18:38:37 215416 dinov2 helpers.py:102] Training  [   800/160000]  eta: 20:13:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0428 (14.4894)  dino_local_crops_loss: 10.1325 (10.2227)  dino_global_crops_loss: 1.0156 (1.0225)  koleo_loss: 0.0949 (0.4295)  ibot_loss: 2.8104 (2.8147)  time: 0.488202  data: 0.253533  max mem: 8193
I20240923 18:38:41 215416 dinov2 helpers.py:102] Training  [   810/160000]  eta: 20:12:10  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0386 (14.4843)  dino_local_crops_loss: 10.1174 (10.2217)  dino_global_crops_loss: 1.0157 (1.0225)  koleo_loss: 0.0978 (0.4255)  ibot_loss: 2.8104 (2.8147)  time: 0.498045  data: 0.261416  max mem: 8193
I20240923 18:38:45 215416 dinov2 helpers.py:102] Training  [   820/160000]  eta: 20:10:17  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0483 (14.4789)  dino_local_crops_loss: 10.1193 (10.2204)  dino_global_crops_loss: 1.0154 (1.0223)  koleo_loss: 0.0989 (0.4215)  ibot_loss: 2.8090 (2.8146)  time: 0.407385  data: 0.169555  max mem: 8193
I20240923 18:38:49 215416 dinov2 helpers.py:102] Training  [   830/160000]  eta: 20:09:27  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0483 (14.4735)  dino_local_crops_loss: 10.1288 (10.2193)  dino_global_crops_loss: 1.0106 (1.0222)  koleo_loss: 0.0919 (0.4175)  ibot_loss: 2.8095 (2.8145)  time: 0.416771  data: 0.174382  max mem: 8193
I20240923 18:38:55 215416 dinov2 helpers.py:102] Training  [   840/160000]  eta: 20:12:45  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0451 (14.4684)  dino_local_crops_loss: 10.1288 (10.2182)  dino_global_crops_loss: 1.0106 (1.0221)  koleo_loss: 0.0900 (0.4136)  ibot_loss: 2.8098 (2.8145)  time: 0.497609  data: 0.254906  max mem: 8193
I20240923 18:38:59 215416 dinov2 helpers.py:102] Training  [   850/160000]  eta: 20:10:37  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0412 (14.4632)  dino_local_crops_loss: 10.1262 (10.2169)  dino_global_crops_loss: 1.0113 (1.0220)  koleo_loss: 0.0914 (0.4099)  ibot_loss: 2.8090 (2.8144)  time: 0.476917  data: 0.242066  max mem: 8193
I20240923 18:39:03 215416 dinov2 helpers.py:102] Training  [   860/160000]  eta: 20:09:56  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0287 (14.4582)  dino_local_crops_loss: 10.1262 (10.2159)  dino_global_crops_loss: 1.0115 (1.0219)  koleo_loss: 0.0811 (0.4060)  ibot_loss: 2.8100 (2.8144)  time: 0.414032  data: 0.172039  max mem: 8193
I20240923 18:39:07 215416 dinov2 helpers.py:102] Training  [   870/160000]  eta: 20:09:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0264 (14.4533)  dino_local_crops_loss: 10.1298 (10.2150)  dino_global_crops_loss: 1.0125 (1.0218)  koleo_loss: 0.0770 (0.4022)  ibot_loss: 2.8104 (2.8143)  time: 0.434148  data: 0.181064  max mem: 8193
I20240923 18:39:13 215416 dinov2 helpers.py:102] Training  [   880/160000]  eta: 20:11:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0199 (14.4483)  dino_local_crops_loss: 10.1167 (10.2137)  dino_global_crops_loss: 1.0115 (1.0217)  koleo_loss: 0.0807 (0.3986)  ibot_loss: 2.8100 (2.8143)  time: 0.489066  data: 0.244830  max mem: 8193
I20240923 18:39:17 215416 dinov2 helpers.py:102] Training  [   890/160000]  eta: 20:10:17  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0141 (14.4433)  dino_local_crops_loss: 10.1030 (10.2125)  dino_global_crops_loss: 1.0114 (1.0215)  koleo_loss: 0.0817 (0.3951)  ibot_loss: 2.8102 (2.8142)  time: 0.478151  data: 0.243782  max mem: 8193
I20240923 18:39:21 215416 dinov2 helpers.py:102] Training  [   900/160000]  eta: 20:08:45  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0141 (14.4386)  dino_local_crops_loss: 10.1154 (10.2115)  dino_global_crops_loss: 1.0114 (1.0214)  koleo_loss: 0.0794 (0.3916)  ibot_loss: 2.8095 (2.8141)  time: 0.408309  data: 0.173173  max mem: 8193
I20240923 18:39:25 215416 dinov2 helpers.py:102] Training  [   910/160000]  eta: 20:06:45  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0028 (14.4339)  dino_local_crops_loss: 10.1103 (10.2103)  dino_global_crops_loss: 1.0129 (1.0214)  koleo_loss: 0.0759 (0.3881)  ibot_loss: 2.8100 (2.8141)  time: 0.398450  data: 0.163648  max mem: 8193
I20240923 18:39:31 215416 dinov2 helpers.py:102] Training  [   920/160000]  eta: 20:11:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9941 (14.4290)  dino_local_crops_loss: 10.0977 (10.2090)  dino_global_crops_loss: 1.0096 (1.0212)  koleo_loss: 0.0769 (0.3847)  ibot_loss: 2.8093 (2.8140)  time: 0.500726  data: 0.255454  max mem: 8193
I20240923 18:39:35 215416 dinov2 helpers.py:102] Training  [   930/160000]  eta: 20:09:22  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9866 (14.4245)  dino_local_crops_loss: 10.0971 (10.2080)  dino_global_crops_loss: 1.0090 (1.0211)  koleo_loss: 0.0739 (0.3814)  ibot_loss: 2.8085 (2.8140)  time: 0.503817  data: 0.259301  max mem: 8193
I20240923 18:39:39 215416 dinov2 helpers.py:102] Training  [   940/160000]  eta: 20:08:15  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0167 (14.4200)  dino_local_crops_loss: 10.1196 (10.2070)  dino_global_crops_loss: 1.0108 (1.0210)  koleo_loss: 0.0739 (0.3782)  ibot_loss: 2.8078 (2.8139)  time: 0.407418  data: 0.168170  max mem: 8193
I20240923 18:39:43 215416 dinov2 helpers.py:102] Training  [   950/160000]  eta: 20:06:31  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 14.0156 (14.4157)  dino_local_crops_loss: 10.1064 (10.2060)  dino_global_crops_loss: 1.0108 (1.0209)  koleo_loss: 0.0671 (0.3749)  ibot_loss: 2.8078 (2.8139)  time: 0.407799  data: 0.166134  max mem: 8193
I20240923 18:39:49 215416 dinov2 helpers.py:102] Training  [   960/160000]  eta: 20:09:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9929 (14.4113)  dino_local_crops_loss: 10.1055 (10.2050)  dino_global_crops_loss: 1.0110 (1.0208)  koleo_loss: 0.0657 (0.3717)  ibot_loss: 2.8076 (2.8138)  time: 0.486085  data: 0.246960  max mem: 8193
I20240923 18:39:53 215416 dinov2 helpers.py:102] Training  [   970/160000]  eta: 20:08:37  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9888 (14.4070)  dino_local_crops_loss: 10.1028 (10.2040)  dino_global_crops_loss: 1.0120 (1.0208)  koleo_loss: 0.0679 (0.3685)  ibot_loss: 2.8076 (2.8137)  time: 0.496353  data: 0.252564  max mem: 8193
I20240923 18:39:57 215416 dinov2 helpers.py:102] Training  [   980/160000]  eta: 20:07:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9954 (14.4028)  dino_local_crops_loss: 10.1028 (10.2029)  dino_global_crops_loss: 1.0134 (1.0207)  koleo_loss: 0.0706 (0.3655)  ibot_loss: 2.8072 (2.8137)  time: 0.410916  data: 0.169013  max mem: 8193
I20240923 18:40:01 215416 dinov2 helpers.py:102] Training  [   990/160000]  eta: 20:05:33  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9740 (14.3982)  dino_local_crops_loss: 10.0875 (10.2015)  dino_global_crops_loss: 1.0070 (1.0205)  koleo_loss: 0.0706 (0.3625)  ibot_loss: 2.8068 (2.8136)  time: 0.401459  data: 0.166090  max mem: 8193
I20240923 18:40:07 215416 dinov2 helpers.py:102] Training  [  1000/160000]  eta: 20:08:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9700 (14.3941)  dino_local_crops_loss: 10.0883 (10.2005)  dino_global_crops_loss: 1.0070 (1.0204)  koleo_loss: 0.0662 (0.3596)  ibot_loss: 2.8074 (2.8135)  time: 0.481929  data: 0.247739  max mem: 8193
I20240923 18:40:11 215416 dinov2 helpers.py:102] Training  [  1010/160000]  eta: 20:07:31  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9732 (14.3898)  dino_local_crops_loss: 10.0905 (10.1993)  dino_global_crops_loss: 1.0102 (1.0203)  koleo_loss: 0.0647 (0.3567)  ibot_loss: 2.8069 (2.8135)  time: 0.495424  data: 0.255022  max mem: 8193
I20240923 18:40:15 215416 dinov2 helpers.py:102] Training  [  1020/160000]  eta: 20:05:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9732 (14.3858)  dino_local_crops_loss: 10.0915 (10.1984)  dino_global_crops_loss: 1.0101 (1.0202)  koleo_loss: 0.0602 (0.3538)  ibot_loss: 2.8069 (2.8134)  time: 0.406200  data: 0.167345  max mem: 8193
I20240923 18:40:19 215416 dinov2 helpers.py:102] Training  [  1030/160000]  eta: 20:04:04  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9842 (14.3819)  dino_local_crops_loss: 10.1086 (10.1975)  dino_global_crops_loss: 1.0101 (1.0202)  koleo_loss: 0.0583 (0.3509)  ibot_loss: 2.8079 (2.8134)  time: 0.391333  data: 0.160229  max mem: 8193
I20240923 18:40:25 215416 dinov2 helpers.py:102] Training  [  1040/160000]  eta: 20:07:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9773 (14.3779)  dino_local_crops_loss: 10.1066 (10.1965)  dino_global_crops_loss: 1.0097 (1.0200)  koleo_loss: 0.0546 (0.3481)  ibot_loss: 2.8074 (2.8133)  time: 0.494714  data: 0.253471  max mem: 8193
I20240923 18:40:29 215416 dinov2 helpers.py:102] Training  [  1050/160000]  eta: 20:05:39  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9687 (14.3739)  dino_local_crops_loss: 10.0981 (10.1955)  dino_global_crops_loss: 1.0129 (1.0200)  koleo_loss: 0.0540 (0.3453)  ibot_loss: 2.8054 (2.8132)  time: 0.488979  data: 0.246624  max mem: 8193
I20240923 18:40:33 215416 dinov2 helpers.py:102] Training  [  1060/160000]  eta: 20:05:07  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9687 (14.3700)  dino_local_crops_loss: 10.0946 (10.1944)  dino_global_crops_loss: 1.0129 (1.0199)  koleo_loss: 0.0547 (0.3426)  ibot_loss: 2.8053 (2.8131)  time: 0.410429  data: 0.168850  max mem: 8193
I20240923 18:40:37 215416 dinov2 helpers.py:102] Training  [  1070/160000]  eta: 20:03:12  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9582 (14.3661)  dino_local_crops_loss: 10.0922 (10.1934)  dino_global_crops_loss: 1.0069 (1.0198)  koleo_loss: 0.0560 (0.3399)  ibot_loss: 2.8048 (2.8130)  time: 0.408521  data: 0.167814  max mem: 8193
I20240923 18:40:43 215416 dinov2 helpers.py:102] Training  [  1080/160000]  eta: 20:06:43  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9592 (14.3625)  dino_local_crops_loss: 10.0901 (10.1925)  dino_global_crops_loss: 1.0087 (1.0197)  koleo_loss: 0.0558 (0.3373)  ibot_loss: 2.8052 (2.8130)  time: 0.490633  data: 0.251734  max mem: 8193
I20240923 18:40:47 215416 dinov2 helpers.py:102] Training  [  1090/160000]  eta: 20:05:04  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9619 (14.3588)  dino_local_crops_loss: 10.0876 (10.1916)  dino_global_crops_loss: 1.0096 (1.0196)  koleo_loss: 0.0573 (0.3348)  ibot_loss: 2.8043 (2.8129)  time: 0.495898  data: 0.255087  max mem: 8193
I20240923 18:40:51 215416 dinov2 helpers.py:102] Training  [  1100/160000]  eta: 20:04:26  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9457 (14.3550)  dino_local_crops_loss: 10.0792 (10.1905)  dino_global_crops_loss: 1.0082 (1.0195)  koleo_loss: 0.0560 (0.3322)  ibot_loss: 2.8029 (2.8128)  time: 0.411436  data: 0.169073  max mem: 8193
I20240923 18:40:55 215416 dinov2 helpers.py:102] Training  [  1110/160000]  eta: 20:03:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9295 (14.3512)  dino_local_crops_loss: 10.0684 (10.1894)  dino_global_crops_loss: 1.0071 (1.0194)  koleo_loss: 0.0515 (0.3297)  ibot_loss: 2.8023 (2.8127)  time: 0.434165  data: 0.182553  max mem: 8193
I20240923 18:41:01 215416 dinov2 helpers.py:102] Training  [  1120/160000]  eta: 20:05:53  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9195 (14.3475)  dino_local_crops_loss: 10.0621 (10.1884)  dino_global_crops_loss: 1.0065 (1.0193)  koleo_loss: 0.0518 (0.3273)  ibot_loss: 2.8010 (2.8126)  time: 0.488443  data: 0.245551  max mem: 8193
I20240923 18:41:05 215416 dinov2 helpers.py:102] Training  [  1130/160000]  eta: 20:04:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9480 (14.3440)  dino_local_crops_loss: 10.0814 (10.1875)  dino_global_crops_loss: 1.0090 (1.0192)  koleo_loss: 0.0526 (0.3249)  ibot_loss: 2.8001 (2.8125)  time: 0.466966  data: 0.234414  max mem: 8193
I20240923 18:41:09 215416 dinov2 helpers.py:102] Training  [  1140/160000]  eta: 20:02:57  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9512 (14.3406)  dino_local_crops_loss: 10.0927 (10.1867)  dino_global_crops_loss: 1.0105 (1.0191)  koleo_loss: 0.0506 (0.3225)  ibot_loss: 2.7995 (2.8123)  time: 0.395463  data: 0.162857  max mem: 8193
I20240923 18:41:13 215416 dinov2 helpers.py:102] Training  [  1150/160000]  eta: 20:01:33  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9554 (14.3372)  dino_local_crops_loss: 10.0921 (10.1858)  dino_global_crops_loss: 1.0105 (1.0190)  koleo_loss: 0.0581 (0.3202)  ibot_loss: 2.7970 (2.8122)  time: 0.397252  data: 0.164118  max mem: 8193
I20240923 18:41:18 215416 dinov2 helpers.py:102] Training  [  1160/160000]  eta: 20:04:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9427 (14.3338)  dino_local_crops_loss: 10.0873 (10.1849)  dino_global_crops_loss: 1.0094 (1.0189)  koleo_loss: 0.0529 (0.3178)  ibot_loss: 2.7970 (2.8121)  time: 0.483613  data: 0.242406  max mem: 8193
I20240923 18:41:22 215416 dinov2 helpers.py:102] Training  [  1170/160000]  eta: 20:02:53  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9194 (14.3302)  dino_local_crops_loss: 10.0655 (10.1840)  dino_global_crops_loss: 1.0076 (1.0188)  koleo_loss: 0.0453 (0.3155)  ibot_loss: 2.7967 (2.8119)  time: 0.486565  data: 0.247420  max mem: 8193
I20240923 18:41:27 215416 dinov2 helpers.py:102] Training  [  1180/160000]  eta: 20:01:50  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9150 (14.3268)  dino_local_crops_loss: 10.0655 (10.1830)  dino_global_crops_loss: 1.0058 (1.0187)  koleo_loss: 0.0453 (0.3132)  ibot_loss: 2.7963 (2.8118)  time: 0.407236  data: 0.176484  max mem: 8193
I20240923 18:41:31 215416 dinov2 helpers.py:102] Training  [  1190/160000]  eta: 20:00:52  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9278 (14.3235)  dino_local_crops_loss: 10.0770 (10.1822)  dino_global_crops_loss: 1.0078 (1.0187)  koleo_loss: 0.0469 (0.3110)  ibot_loss: 2.7949 (2.8117)  time: 0.412568  data: 0.178770  max mem: 8193
I20240923 18:41:37 215416 dinov2 helpers.py:102] Training  [  1200/160000]  eta: 20:03:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9321 (14.3202)  dino_local_crops_loss: 10.0785 (10.1813)  dino_global_crops_loss: 1.0093 (1.0186)  koleo_loss: 0.0439 (0.3088)  ibot_loss: 2.7941 (2.8115)  time: 0.501736  data: 0.254924  max mem: 8193
I20240923 18:41:41 215416 dinov2 helpers.py:102] Training  [  1210/160000]  eta: 20:02:51  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9222 (14.3168)  dino_local_crops_loss: 10.0777 (10.1804)  dino_global_crops_loss: 1.0068 (1.0185)  koleo_loss: 0.0439 (0.3066)  ibot_loss: 2.7931 (2.8113)  time: 0.502654  data: 0.256200  max mem: 8193
I20240923 18:41:45 215416 dinov2 helpers.py:102] Training  [  1220/160000]  eta: 20:02:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9053 (14.3135)  dino_local_crops_loss: 10.0622 (10.1794)  dino_global_crops_loss: 1.0067 (1.0184)  koleo_loss: 0.0453 (0.3044)  ibot_loss: 2.7924 (2.8112)  time: 0.421346  data: 0.179006  max mem: 8193
I20240923 18:41:49 215416 dinov2 helpers.py:102] Training  [  1230/160000]  eta: 20:00:52  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9077 (14.3102)  dino_local_crops_loss: 10.0663 (10.1785)  dino_global_crops_loss: 1.0083 (1.0183)  koleo_loss: 0.0437 (0.3023)  ibot_loss: 2.7912 (2.8110)  time: 0.411960  data: 0.168694  max mem: 8193
I20240923 18:41:55 215416 dinov2 helpers.py:102] Training  [  1240/160000]  eta: 20:03:28  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9205 (14.3070)  dino_local_crops_loss: 10.0771 (10.1777)  dino_global_crops_loss: 1.0092 (1.0182)  koleo_loss: 0.0420 (0.3002)  ibot_loss: 2.7904 (2.8109)  time: 0.487727  data: 0.249744  max mem: 8193
I20240923 18:41:59 215416 dinov2 helpers.py:102] Training  [  1250/160000]  eta: 20:02:23  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9186 (14.3038)  dino_local_crops_loss: 10.0771 (10.1768)  dino_global_crops_loss: 1.0055 (1.0182)  koleo_loss: 0.0399 (0.2981)  ibot_loss: 2.7895 (2.8107)  time: 0.493179  data: 0.256941  max mem: 8193
I20240923 18:42:03 215416 dinov2 helpers.py:102] Training  [  1260/160000]  eta: 20:01:25  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9041 (14.3007)  dino_local_crops_loss: 10.0702 (10.1760)  dino_global_crops_loss: 1.0062 (1.0181)  koleo_loss: 0.0389 (0.2961)  ibot_loss: 2.7883 (2.8105)  time: 0.409605  data: 0.173586  max mem: 8193
I20240923 18:42:07 215416 dinov2 helpers.py:102] Training  [  1270/160000]  eta: 20:00:18  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9077 (14.2976)  dino_local_crops_loss: 10.0805 (10.1752)  dino_global_crops_loss: 1.0077 (1.0180)  koleo_loss: 0.0396 (0.2941)  ibot_loss: 2.7880 (2.8103)  time: 0.407821  data: 0.171935  max mem: 8193
I20240923 18:42:13 215416 dinov2 helpers.py:102] Training  [  1280/160000]  eta: 20:02:43  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9019 (14.2946)  dino_local_crops_loss: 10.0767 (10.1744)  dino_global_crops_loss: 1.0068 (1.0179)  koleo_loss: 0.0410 (0.2921)  ibot_loss: 2.7873 (2.8101)  time: 0.489322  data: 0.256576  max mem: 8193
I20240923 18:42:17 215416 dinov2 helpers.py:102] Training  [  1290/160000]  eta: 20:01:48  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8987 (14.2915)  dino_local_crops_loss: 10.0672 (10.1736)  dino_global_crops_loss: 1.0070 (1.0178)  koleo_loss: 0.0378 (0.2901)  ibot_loss: 2.7865 (2.8100)  time: 0.493996  data: 0.262040  max mem: 8193
I20240923 18:42:21 215416 dinov2 helpers.py:102] Training  [  1300/160000]  eta: 20:00:50  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9081 (14.2886)  dino_local_crops_loss: 10.0745 (10.1728)  dino_global_crops_loss: 1.0075 (1.0178)  koleo_loss: 0.0357 (0.2882)  ibot_loss: 2.7854 (2.8098)  time: 0.411893  data: 0.176179  max mem: 8193
I20240923 18:42:25 215416 dinov2 helpers.py:102] Training  [  1310/160000]  eta: 19:59:42  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.9014 (14.2856)  dino_local_crops_loss: 10.0729 (10.1720)  dino_global_crops_loss: 1.0068 (1.0177)  koleo_loss: 0.0375 (0.2863)  ibot_loss: 2.7853 (2.8096)  time: 0.406026  data: 0.167413  max mem: 8193
I20240923 18:42:31 215416 dinov2 helpers.py:102] Training  [  1320/160000]  eta: 20:02:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8968 (14.2827)  dino_local_crops_loss: 10.0693 (10.1713)  dino_global_crops_loss: 1.0064 (1.0176)  koleo_loss: 0.0357 (0.2844)  ibot_loss: 2.7851 (2.8094)  time: 0.495987  data: 0.252886  max mem: 8193
I20240923 18:42:35 215416 dinov2 helpers.py:102] Training  [  1330/160000]  eta: 20:01:18  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8948 (14.2797)  dino_local_crops_loss: 10.0691 (10.1705)  dino_global_crops_loss: 1.0054 (1.0175)  koleo_loss: 0.0357 (0.2825)  ibot_loss: 2.7841 (2.8092)  time: 0.497681  data: 0.257031  max mem: 8193
I20240923 18:42:39 215416 dinov2 helpers.py:102] Training  [  1340/160000]  eta: 20:00:35  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8868 (14.2768)  dino_local_crops_loss: 10.0626 (10.1697)  dino_global_crops_loss: 1.0045 (1.0174)  koleo_loss: 0.0349 (0.2807)  ibot_loss: 2.7827 (2.8090)  time: 0.413436  data: 0.173676  max mem: 8193
I20240923 18:42:43 215416 dinov2 helpers.py:102] Training  [  1350/160000]  eta: 19:59:33  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8917 (14.2740)  dino_local_crops_loss: 10.0662 (10.1689)  dino_global_crops_loss: 1.0057 (1.0173)  koleo_loss: 0.0352 (0.2789)  ibot_loss: 2.7822 (2.8088)  time: 0.413413  data: 0.171712  max mem: 8193
I20240923 18:42:49 215416 dinov2 helpers.py:102] Training  [  1360/160000]  eta: 20:02:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8997 (14.2712)  dino_local_crops_loss: 10.0709 (10.1683)  dino_global_crops_loss: 1.0063 (1.0173)  koleo_loss: 0.0392 (0.2771)  ibot_loss: 2.7819 (2.8086)  time: 0.497249  data: 0.253337  max mem: 8193
I20240923 18:42:53 215416 dinov2 helpers.py:102] Training  [  1370/160000]  eta: 20:01:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8922 (14.2685)  dino_local_crops_loss: 10.0749 (10.1676)  dino_global_crops_loss: 1.0061 (1.0172)  koleo_loss: 0.0330 (0.2753)  ibot_loss: 2.7815 (2.8084)  time: 0.496861  data: 0.253848  max mem: 8193
I20240923 18:42:57 215416 dinov2 helpers.py:102] Training  [  1380/160000]  eta: 20:00:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8890 (14.2658)  dino_local_crops_loss: 10.0690 (10.1668)  dino_global_crops_loss: 1.0064 (1.0171)  koleo_loss: 0.0334 (0.2736)  ibot_loss: 2.7812 (2.8082)  time: 0.405015  data: 0.169564  max mem: 8193
I20240923 18:43:02 215416 dinov2 helpers.py:102] Training  [  1390/160000]  eta: 19:59:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8918 (14.2631)  dino_local_crops_loss: 10.0640 (10.1661)  dino_global_crops_loss: 1.0068 (1.0171)  koleo_loss: 0.0349 (0.2719)  ibot_loss: 2.7806 (2.8080)  time: 0.413167  data: 0.177262  max mem: 8193
I20240923 18:43:07 215416 dinov2 helpers.py:102] Training  [  1400/160000]  eta: 20:01:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8939 (14.2604)  dino_local_crops_loss: 10.0709 (10.1655)  dino_global_crops_loss: 1.0077 (1.0170)  koleo_loss: 0.0315 (0.2701)  ibot_loss: 2.7806 (2.8078)  time: 0.503756  data: 0.265371  max mem: 8193
I20240923 18:43:11 215416 dinov2 helpers.py:102] Training  [  1410/160000]  eta: 20:00:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8871 (14.2578)  dino_local_crops_loss: 10.0677 (10.1648)  dino_global_crops_loss: 1.0071 (1.0169)  koleo_loss: 0.0315 (0.2685)  ibot_loss: 2.7799 (2.8076)  time: 0.495946  data: 0.257348  max mem: 8193
I20240923 18:43:16 215416 dinov2 helpers.py:102] Training  [  1420/160000]  eta: 19:59:56  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8820 (14.2551)  dino_local_crops_loss: 10.0624 (10.1641)  dino_global_crops_loss: 1.0071 (1.0169)  koleo_loss: 0.0319 (0.2668)  ibot_loss: 2.7798 (2.8074)  time: 0.409205  data: 0.172487  max mem: 8193
I20240923 18:43:20 215416 dinov2 helpers.py:102] Training  [  1430/160000]  eta: 19:59:26  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8805 (14.2526)  dino_local_crops_loss: 10.0661 (10.1634)  dino_global_crops_loss: 1.0068 (1.0168)  koleo_loss: 0.0273 (0.2651)  ibot_loss: 2.7790 (2.8072)  time: 0.422005  data: 0.180261  max mem: 8193
I20240923 18:43:26 215416 dinov2 helpers.py:102] Training  [  1440/160000]  eta: 20:01:24  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8848 (14.2500)  dino_local_crops_loss: 10.0737 (10.1628)  dino_global_crops_loss: 1.0067 (1.0167)  koleo_loss: 0.0250 (0.2635)  ibot_loss: 2.7787 (2.8070)  time: 0.497823  data: 0.256375  max mem: 8193
I20240923 18:43:30 215416 dinov2 helpers.py:102] Training  [  1450/160000]  eta: 20:00:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8874 (14.2475)  dino_local_crops_loss: 10.0771 (10.1622)  dino_global_crops_loss: 1.0069 (1.0167)  koleo_loss: 0.0260 (0.2619)  ibot_loss: 2.7786 (2.8068)  time: 0.483030  data: 0.247772  max mem: 8193
I20240923 18:43:34 215416 dinov2 helpers.py:102] Training  [  1460/160000]  eta: 19:59:52  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8878 (14.2451)  dino_local_crops_loss: 10.0765 (10.1616)  dino_global_crops_loss: 1.0077 (1.0166)  koleo_loss: 0.0315 (0.2603)  ibot_loss: 2.7778 (2.8066)  time: 0.416407  data: 0.174915  max mem: 8193
I20240923 18:43:38 215416 dinov2 helpers.py:102] Training  [  1470/160000]  eta: 19:58:39  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8842 (14.2426)  dino_local_crops_loss: 10.0706 (10.1610)  dino_global_crops_loss: 1.0072 (1.0165)  koleo_loss: 0.0270 (0.2587)  ibot_loss: 2.7774 (2.8064)  time: 0.411182  data: 0.167300  max mem: 8193
I20240923 18:43:44 215416 dinov2 helpers.py:102] Training  [  1480/160000]  eta: 20:00:59  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8827 (14.2402)  dino_local_crops_loss: 10.0671 (10.1604)  dino_global_crops_loss: 1.0072 (1.0165)  koleo_loss: 0.0272 (0.2571)  ibot_loss: 2.7775 (2.8062)  time: 0.489620  data: 0.251195  max mem: 8193
I20240923 18:43:48 215416 dinov2 helpers.py:102] Training  [  1490/160000]  eta: 20:00:01  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8847 (14.2378)  dino_local_crops_loss: 10.0728 (10.1598)  dino_global_crops_loss: 1.0082 (1.0164)  koleo_loss: 0.0259 (0.2556)  ibot_loss: 2.7773 (2.8060)  time: 0.496555  data: 0.261290  max mem: 8193
I20240923 18:43:52 215416 dinov2 helpers.py:102] Training  [  1500/160000]  eta: 19:59:05  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8833 (14.2354)  dino_local_crops_loss: 10.0728 (10.1592)  dino_global_crops_loss: 1.0082 (1.0164)  koleo_loss: 0.0247 (0.2540)  ibot_loss: 2.7768 (2.8058)  time: 0.404983  data: 0.172868  max mem: 8193
I20240923 18:43:56 215416 dinov2 helpers.py:102] Training  [  1510/160000]  eta: 19:57:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8867 (14.2332)  dino_local_crops_loss: 10.0737 (10.1587)  dino_global_crops_loss: 1.0087 (1.0163)  koleo_loss: 0.0256 (0.2525)  ibot_loss: 2.7767 (2.8056)  time: 0.398799  data: 0.167258  max mem: 8193
I20240923 18:44:02 215416 dinov2 helpers.py:102] Training  [  1520/160000]  eta: 20:00:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8900 (14.2309)  dino_local_crops_loss: 10.0774 (10.1581)  dino_global_crops_loss: 1.0089 (1.0163)  koleo_loss: 0.0256 (0.2510)  ibot_loss: 2.7765 (2.8054)  time: 0.487675  data: 0.252165  max mem: 8193
I20240923 18:44:06 215416 dinov2 helpers.py:102] Training  [  1530/160000]  eta: 19:59:42  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8832 (14.2286)  dino_local_crops_loss: 10.0704 (10.1576)  dino_global_crops_loss: 1.0074 (1.0162)  koleo_loss: 0.0244 (0.2496)  ibot_loss: 2.7765 (2.8052)  time: 0.509153  data: 0.263747  max mem: 8193
I20240923 18:44:10 215416 dinov2 helpers.py:102] Training  [  1540/160000]  eta: 19:58:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8833 (14.2264)  dino_local_crops_loss: 10.0729 (10.1571)  dino_global_crops_loss: 1.0081 (1.0162)  koleo_loss: 0.0226 (0.2481)  ibot_loss: 2.7758 (2.8051)  time: 0.407727  data: 0.164566  max mem: 8193
I20240923 18:44:14 215416 dinov2 helpers.py:102] Training  [  1550/160000]  eta: 19:58:07  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8808 (14.2241)  dino_local_crops_loss: 10.0783 (10.1566)  dino_global_crops_loss: 1.0088 (1.0161)  koleo_loss: 0.0200 (0.2466)  ibot_loss: 2.7756 (2.8049)  time: 0.412476  data: 0.170517  max mem: 8193
I20240923 18:44:20 215416 dinov2 helpers.py:102] Training  [  1560/160000]  eta: 20:00:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8812 (14.2219)  dino_local_crops_loss: 10.0783 (10.1560)  dino_global_crops_loss: 1.0079 (1.0161)  koleo_loss: 0.0205 (0.2452)  ibot_loss: 2.7756 (2.8047)  time: 0.526808  data: 0.272265  max mem: 8193
I20240923 18:44:24 215416 dinov2 helpers.py:102] Training  [  1570/160000]  eta: 19:59:36  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8800 (14.2197)  dino_local_crops_loss: 10.0743 (10.1555)  dino_global_crops_loss: 1.0071 (1.0160)  koleo_loss: 0.0223 (0.2437)  ibot_loss: 2.7752 (2.8045)  time: 0.502168  data: 0.255428  max mem: 8193
I20240923 18:44:28 215416 dinov2 helpers.py:102] Training  [  1580/160000]  eta: 19:58:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8777 (14.2176)  dino_local_crops_loss: 10.0732 (10.1550)  dino_global_crops_loss: 1.0071 (1.0159)  koleo_loss: 0.0233 (0.2423)  ibot_loss: 2.7746 (2.8043)  time: 0.402457  data: 0.166622  max mem: 8193
I20240923 18:44:33 215416 dinov2 helpers.py:102] Training  [  1590/160000]  eta: 19:58:42  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8751 (14.2154)  dino_local_crops_loss: 10.0723 (10.1545)  dino_global_crops_loss: 1.0074 (1.0159)  koleo_loss: 0.0220 (0.2409)  ibot_loss: 2.7745 (2.8041)  time: 0.431899  data: 0.186550  max mem: 8193
I20240923 18:44:39 215416 dinov2 helpers.py:102] Training  [  1600/160000]  eta: 20:00:44  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8742 (14.2133)  dino_local_crops_loss: 10.0734 (10.1540)  dino_global_crops_loss: 1.0074 (1.0158)  koleo_loss: 0.0194 (0.2396)  ibot_loss: 2.7743 (2.8039)  time: 0.518055  data: 0.272978  max mem: 8193
I20240923 18:44:43 215416 dinov2 helpers.py:102] Training  [  1610/160000]  eta: 20:00:28  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8742 (14.2112)  dino_local_crops_loss: 10.0726 (10.1535)  dino_global_crops_loss: 1.0078 (1.0158)  koleo_loss: 0.0197 (0.2382)  ibot_loss: 2.7742 (2.8037)  time: 0.512513  data: 0.265648  max mem: 8193
I20240923 18:44:47 215416 dinov2 helpers.py:102] Training  [  1620/160000]  eta: 19:59:15  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8730 (14.2091)  dino_local_crops_loss: 10.0723 (10.1530)  dino_global_crops_loss: 1.0079 (1.0157)  koleo_loss: 0.0197 (0.2368)  ibot_loss: 2.7741 (2.8036)  time: 0.413810  data: 0.165813  max mem: 8193
I20240923 18:44:51 215416 dinov2 helpers.py:102] Training  [  1630/160000]  eta: 19:58:55  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8754 (14.2071)  dino_local_crops_loss: 10.0744 (10.1525)  dino_global_crops_loss: 1.0076 (1.0157)  koleo_loss: 0.0199 (0.2355)  ibot_loss: 2.7739 (2.8034)  time: 0.411353  data: 0.167796  max mem: 8193
I20240923 18:44:57 215416 dinov2 helpers.py:102] Training  [  1640/160000]  eta: 20:00:43  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8783 (14.2051)  dino_local_crops_loss: 10.0795 (10.1521)  dino_global_crops_loss: 1.0076 (1.0156)  koleo_loss: 0.0167 (0.2342)  ibot_loss: 2.7742 (2.8032)  time: 0.504487  data: 0.263448  max mem: 8193
I20240923 18:45:01 215416 dinov2 helpers.py:102] Training  [  1650/160000]  eta: 20:00:18  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8771 (14.2031)  dino_local_crops_loss: 10.0758 (10.1516)  dino_global_crops_loss: 1.0079 (1.0156)  koleo_loss: 0.0162 (0.2329)  ibot_loss: 2.7739 (2.8030)  time: 0.502278  data: 0.260871  max mem: 8193
I20240923 18:45:05 215416 dinov2 helpers.py:102] Training  [  1660/160000]  eta: 19:59:13  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8770 (14.2011)  dino_local_crops_loss: 10.0760 (10.1512)  dino_global_crops_loss: 1.0080 (1.0156)  koleo_loss: 0.0194 (0.2316)  ibot_loss: 2.7732 (2.8028)  time: 0.412677  data: 0.169873  max mem: 8193
I20240923 18:45:09 215416 dinov2 helpers.py:102] Training  [  1670/160000]  eta: 19:58:31  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8736 (14.1991)  dino_local_crops_loss: 10.0761 (10.1507)  dino_global_crops_loss: 1.0078 (1.0155)  koleo_loss: 0.0154 (0.2303)  ibot_loss: 2.7733 (2.8027)  time: 0.403211  data: 0.167291  max mem: 8193
I20240923 18:45:16 215416 dinov2 helpers.py:102] Training  [  1680/160000]  eta: 20:01:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8720 (14.1972)  dino_local_crops_loss: 10.0762 (10.1503)  dino_global_crops_loss: 1.0078 (1.0155)  koleo_loss: 0.0147 (0.2290)  ibot_loss: 2.7735 (2.8025)  time: 0.519428  data: 0.276524  max mem: 8193
I20240923 18:45:20 215416 dinov2 helpers.py:102] Training  [  1690/160000]  eta: 20:00:12  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8759 (14.1953)  dino_local_crops_loss: 10.0784 (10.1499)  dino_global_crops_loss: 1.0086 (1.0154)  koleo_loss: 0.0146 (0.2277)  ibot_loss: 2.7730 (2.8023)  time: 0.513315  data: 0.271114  max mem: 8193
I20240923 18:45:24 215416 dinov2 helpers.py:102] Training  [  1700/160000]  eta: 19:59:34  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8695 (14.1934)  dino_local_crops_loss: 10.0770 (10.1494)  dino_global_crops_loss: 1.0074 (1.0154)  koleo_loss: 0.0132 (0.2265)  ibot_loss: 2.7730 (2.8021)  time: 0.410175  data: 0.173477  max mem: 8193
I20240923 18:45:28 215416 dinov2 helpers.py:102] Training  [  1710/160000]  eta: 19:59:05  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8691 (14.1915)  dino_local_crops_loss: 10.0752 (10.1490)  dino_global_crops_loss: 1.0074 (1.0153)  koleo_loss: 0.0132 (0.2252)  ibot_loss: 2.7730 (2.8020)  time: 0.423523  data: 0.182324  max mem: 8193
I20240923 18:45:34 215416 dinov2 helpers.py:102] Training  [  1720/160000]  eta: 20:00:59  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8696 (14.1896)  dino_local_crops_loss: 10.0761 (10.1486)  dino_global_crops_loss: 1.0079 (1.0153)  koleo_loss: 0.0117 (0.2240)  ibot_loss: 2.7728 (2.8018)  time: 0.506144  data: 0.268675  max mem: 8193
I20240923 18:45:38 215416 dinov2 helpers.py:102] Training  [  1730/160000]  eta: 20:00:38  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8714 (14.1878)  dino_local_crops_loss: 10.0782 (10.1482)  dino_global_crops_loss: 1.0080 (1.0152)  koleo_loss: 0.0124 (0.2228)  ibot_loss: 2.7723 (2.8016)  time: 0.510377  data: 0.269887  max mem: 8193
I20240923 18:45:43 215416 dinov2 helpers.py:102] Training  [  1740/160000]  eta: 20:00:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8731 (14.1860)  dino_local_crops_loss: 10.0786 (10.1478)  dino_global_crops_loss: 1.0080 (1.0152)  koleo_loss: 0.0120 (0.2216)  ibot_loss: 2.7721 (2.8015)  time: 0.429559  data: 0.182114  max mem: 8193
I20240923 18:45:46 215416 dinov2 helpers.py:102] Training  [  1750/160000]  eta: 19:59:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8719 (14.1842)  dino_local_crops_loss: 10.0786 (10.1474)  dino_global_crops_loss: 1.0078 (1.0152)  koleo_loss: 0.0120 (0.2204)  ibot_loss: 2.7726 (2.8013)  time: 0.407650  data: 0.167622  max mem: 8193
I20240923 18:45:52 215416 dinov2 helpers.py:102] Training  [  1760/160000]  eta: 20:00:53  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8710 (14.1824)  dino_local_crops_loss: 10.0789 (10.1470)  dino_global_crops_loss: 1.0081 (1.0151)  koleo_loss: 0.0120 (0.2192)  ibot_loss: 2.7725 (2.8011)  time: 0.487723  data: 0.246432  max mem: 8193
I20240923 18:45:56 215416 dinov2 helpers.py:102] Training  [  1770/160000]  eta: 20:00:00  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8711 (14.1807)  dino_local_crops_loss: 10.0791 (10.1466)  dino_global_crops_loss: 1.0083 (1.0151)  koleo_loss: 0.0118 (0.2180)  ibot_loss: 2.7717 (2.8010)  time: 0.491377  data: 0.250141  max mem: 8193
I20240923 18:46:00 215416 dinov2 helpers.py:102] Training  [  1780/160000]  eta: 19:59:05  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8710 (14.1789)  dino_local_crops_loss: 10.0787 (10.1462)  dino_global_crops_loss: 1.0083 (1.0150)  koleo_loss: 0.0121 (0.2168)  ibot_loss: 2.7715 (2.8008)  time: 0.399454  data: 0.167014  max mem: 8193
I20240923 18:46:04 215416 dinov2 helpers.py:102] Training  [  1790/160000]  eta: 19:58:27  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8669 (14.1772)  dino_local_crops_loss: 10.0787 (10.1459)  dino_global_crops_loss: 1.0082 (1.0150)  koleo_loss: 0.0076 (0.2157)  ibot_loss: 2.7715 (2.8006)  time: 0.407818  data: 0.173222  max mem: 8193
I20240923 18:46:10 215416 dinov2 helpers.py:102] Training  [  1800/160000]  eta: 20:00:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8662 (14.1755)  dino_local_crops_loss: 10.0787 (10.1455)  dino_global_crops_loss: 1.0083 (1.0150)  koleo_loss: 0.0071 (0.2145)  ibot_loss: 2.7712 (2.8005)  time: 0.495709  data: 0.256302  max mem: 8193
I20240923 18:46:14 215416 dinov2 helpers.py:102] Training  [  1810/160000]  eta: 19:59:35  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8658 (14.1737)  dino_local_crops_loss: 10.0786 (10.1451)  dino_global_crops_loss: 1.0077 (1.0149)  koleo_loss: 0.0079 (0.2134)  ibot_loss: 2.7710 (2.8003)  time: 0.498101  data: 0.255143  max mem: 8193
I20240923 18:46:18 215416 dinov2 helpers.py:102] Training  [  1820/160000]  eta: 19:58:36  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8611 (14.1720)  dino_local_crops_loss: 10.0775 (10.1448)  dino_global_crops_loss: 1.0070 (1.0149)  koleo_loss: 0.0094 (0.2123)  ibot_loss: 2.7710 (2.8002)  time: 0.407577  data: 0.169455  max mem: 8193
I20240923 18:46:23 215416 dinov2 helpers.py:102] Training  [  1830/160000]  eta: 19:58:04  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8656 (14.1704)  dino_local_crops_loss: 10.0788 (10.1444)  dino_global_crops_loss: 1.0075 (1.0148)  koleo_loss: 0.0075 (0.2111)  ibot_loss: 2.7711 (2.8000)  time: 0.407985  data: 0.168684  max mem: 8193
I20240923 18:46:28 215416 dinov2 helpers.py:102] Training  [  1840/160000]  eta: 19:59:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8656 (14.1687)  dino_local_crops_loss: 10.0801 (10.1440)  dino_global_crops_loss: 1.0077 (1.0148)  koleo_loss: 0.0062 (0.2100)  ibot_loss: 2.7715 (2.7998)  time: 0.501655  data: 0.256385  max mem: 8193
I20240923 18:46:33 215416 dinov2 helpers.py:102] Training  [  1850/160000]  eta: 19:59:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8637 (14.1671)  dino_local_crops_loss: 10.0786 (10.1437)  dino_global_crops_loss: 1.0080 (1.0148)  koleo_loss: 0.0061 (0.2089)  ibot_loss: 2.7716 (2.7997)  time: 0.495885  data: 0.254323  max mem: 8193
I20240923 18:46:36 215416 dinov2 helpers.py:102] Training  [  1860/160000]  eta: 19:58:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8663 (14.1655)  dino_local_crops_loss: 10.0817 (10.1434)  dino_global_crops_loss: 1.0081 (1.0147)  koleo_loss: 0.0063 (0.2078)  ibot_loss: 2.7714 (2.7995)  time: 0.401069  data: 0.165562  max mem: 8193
I20240923 18:46:41 215416 dinov2 helpers.py:102] Training  [  1870/160000]  eta: 19:57:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8657 (14.1639)  dino_local_crops_loss: 10.0819 (10.1430)  dino_global_crops_loss: 1.0081 (1.0147)  koleo_loss: 0.0062 (0.2068)  ibot_loss: 2.7711 (2.7994)  time: 0.414804  data: 0.175719  max mem: 8193
I20240923 18:46:46 215416 dinov2 helpers.py:102] Training  [  1880/160000]  eta: 19:59:07  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8681 (14.1623)  dino_local_crops_loss: 10.0816 (10.1427)  dino_global_crops_loss: 1.0079 (1.0147)  koleo_loss: 0.0043 (0.2057)  ibot_loss: 2.7711 (2.7992)  time: 0.495776  data: 0.256644  max mem: 8193
I20240923 18:46:50 215416 dinov2 helpers.py:102] Training  [  1890/160000]  eta: 19:58:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8645 (14.1607)  dino_local_crops_loss: 10.0833 (10.1424)  dino_global_crops_loss: 1.0082 (1.0146)  koleo_loss: 0.0042 (0.2046)  ibot_loss: 2.7706 (2.7991)  time: 0.471878  data: 0.240095  max mem: 8193
I20240923 18:46:54 215416 dinov2 helpers.py:102] Training  [  1900/160000]  eta: 19:57:20  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8625 (14.1591)  dino_local_crops_loss: 10.0830 (10.1420)  dino_global_crops_loss: 1.0082 (1.0146)  koleo_loss: 0.0018 (0.2036)  ibot_loss: 2.7702 (2.7989)  time: 0.396313  data: 0.164353  max mem: 8193
I20240923 18:46:58 215416 dinov2 helpers.py:102] Training  [  1910/160000]  eta: 19:56:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8618 (14.1576)  dino_local_crops_loss: 10.0811 (10.1417)  dino_global_crops_loss: 1.0080 (1.0146)  koleo_loss: 0.0025 (0.2025)  ibot_loss: 2.7702 (2.7988)  time: 0.410145  data: 0.174900  max mem: 8193
I20240923 18:47:04 215416 dinov2 helpers.py:102] Training  [  1920/160000]  eta: 19:58:26  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8631 (14.1561)  dino_local_crops_loss: 10.0824 (10.1414)  dino_global_crops_loss: 1.0082 (1.0145)  koleo_loss: 0.0047 (0.2015)  ibot_loss: 2.7699 (2.7986)  time: 0.500273  data: 0.259123  max mem: 8193
I20240923 18:47:08 215416 dinov2 helpers.py:102] Training  [  1930/160000]  eta: 19:57:45  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8627 (14.1545)  dino_local_crops_loss: 10.0805 (10.1411)  dino_global_crops_loss: 1.0084 (1.0145)  koleo_loss: 0.0062 (0.2005)  ibot_loss: 2.7699 (2.7985)  time: 0.495469  data: 0.257607  max mem: 8193
I20240923 18:47:13 215416 dinov2 helpers.py:102] Training  [  1940/160000]  eta: 19:57:22  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8599 (14.1530)  dino_local_crops_loss: 10.0780 (10.1408)  dino_global_crops_loss: 1.0080 (1.0145)  koleo_loss: 0.0035 (0.1995)  ibot_loss: 2.7700 (2.7983)  time: 0.420751  data: 0.182946  max mem: 8193
I20240923 18:47:17 215416 dinov2 helpers.py:102] Training  [  1950/160000]  eta: 19:56:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8640 (14.1515)  dino_local_crops_loss: 10.0827 (10.1405)  dino_global_crops_loss: 1.0079 (1.0144)  koleo_loss: 0.0039 (0.1985)  ibot_loss: 2.7692 (2.7982)  time: 0.415258  data: 0.177265  max mem: 8193
I20240923 18:47:22 215416 dinov2 helpers.py:102] Training  [  1960/160000]  eta: 19:58:06  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8632 (14.1501)  dino_local_crops_loss: 10.0810 (10.1402)  dino_global_crops_loss: 1.0085 (1.0144)  koleo_loss: 0.0026 (0.1975)  ibot_loss: 2.7695 (2.7980)  time: 0.487468  data: 0.253881  max mem: 8193
I20240923 18:47:27 215416 dinov2 helpers.py:102] Training  [  1970/160000]  eta: 19:57:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8617 (14.1486)  dino_local_crops_loss: 10.0807 (10.1399)  dino_global_crops_loss: 1.0085 (1.0144)  koleo_loss: 0.0005 (0.1965)  ibot_loss: 2.7695 (2.7979)  time: 0.490469  data: 0.254534  max mem: 8193
I20240923 18:47:31 215416 dinov2 helpers.py:102] Training  [  1980/160000]  eta: 19:56:37  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8623 (14.1472)  dino_local_crops_loss: 10.0824 (10.1396)  dino_global_crops_loss: 1.0084 (1.0143)  koleo_loss: 0.0008 (0.1955)  ibot_loss: 2.7686 (2.7977)  time: 0.404759  data: 0.168684  max mem: 8193
I20240923 18:47:35 215416 dinov2 helpers.py:102] Training  [  1990/160000]  eta: 19:56:17  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8587 (14.1457)  dino_local_crops_loss: 10.0816 (10.1393)  dino_global_crops_loss: 1.0086 (1.0143)  koleo_loss: 0.0011 (0.1945)  ibot_loss: 2.7698 (2.7976)  time: 0.420083  data: 0.176239  max mem: 8193
I20240923 18:47:40 215416 dinov2 helpers.py:102] Training  [  2000/160000]  eta: 19:57:23  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8573 (14.1443)  dino_local_crops_loss: 10.0806 (10.1390)  dino_global_crops_loss: 1.0085 (1.0143)  koleo_loss: 0.0011 (0.1936)  ibot_loss: 2.7691 (2.7975)  time: 0.489736  data: 0.246947  max mem: 8193
I20240923 18:47:45 215416 dinov2 helpers.py:102] Training  [  2010/160000]  eta: 19:57:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8605 (14.1429)  dino_local_crops_loss: 10.0816 (10.1387)  dino_global_crops_loss: 1.0085 (1.0142)  koleo_loss: 0.0004 (0.1926)  ibot_loss: 2.7693 (2.7973)  time: 0.493323  data: 0.249115  max mem: 8193
I20240923 18:47:49 215416 dinov2 helpers.py:102] Training  [  2020/160000]  eta: 19:56:14  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8627 (14.1415)  dino_local_crops_loss: 10.0823 (10.1385)  dino_global_crops_loss: 1.0085 (1.0142)  koleo_loss: 0.0006 (0.1917)  ibot_loss: 2.7687 (2.7972)  time: 0.416098  data: 0.172491  max mem: 8193
I20240923 18:47:53 215416 dinov2 helpers.py:102] Training  [  2030/160000]  eta: 19:55:32  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8631 (14.1401)  dino_local_crops_loss: 10.0853 (10.1382)  dino_global_crops_loss: 1.0089 (1.0142)  koleo_loss: 0.0004 (0.1907)  ibot_loss: 2.7685 (2.7970)  time: 0.398242  data: 0.166052  max mem: 8193
I20240923 18:47:59 215416 dinov2 helpers.py:102] Training  [  2040/160000]  eta: 19:57:26  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8597 (14.1388)  dino_local_crops_loss: 10.0846 (10.1379)  dino_global_crops_loss: 1.0082 (1.0142)  koleo_loss: -0.0004 (0.1898)  ibot_loss: 2.7685 (2.7969)  time: 0.506999  data: 0.262278  max mem: 8193
I20240923 18:48:03 215416 dinov2 helpers.py:102] Training  [  2050/160000]  eta: 19:57:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8597 (14.1374)  dino_local_crops_loss: 10.0821 (10.1376)  dino_global_crops_loss: 1.0080 (1.0141)  koleo_loss: 0.0016 (0.1889)  ibot_loss: 2.7682 (2.7967)  time: 0.518964  data: 0.266324  max mem: 8193
I20240923 18:48:07 215416 dinov2 helpers.py:102] Training  [  2060/160000]  eta: 19:56:22  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8576 (14.1361)  dino_local_crops_loss: 10.0818 (10.1374)  dino_global_crops_loss: 1.0082 (1.0141)  koleo_loss: 0.0013 (0.1880)  ibot_loss: 2.7672 (2.7966)  time: 0.418794  data: 0.173958  max mem: 8193
I20240923 18:48:11 215416 dinov2 helpers.py:102] Training  [  2070/160000]  eta: 19:55:37  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8598 (14.1347)  dino_local_crops_loss: 10.0845 (10.1371)  dino_global_crops_loss: 1.0085 (1.0141)  koleo_loss: -0.0022 (0.1870)  ibot_loss: 2.7671 (2.7965)  time: 0.404412  data: 0.164595  max mem: 8193
I20240923 18:48:17 215416 dinov2 helpers.py:102] Training  [  2080/160000]  eta: 19:57:28  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8582 (14.1334)  dino_local_crops_loss: 10.0837 (10.1369)  dino_global_crops_loss: 1.0083 (1.0141)  koleo_loss: -0.0003 (0.1861)  ibot_loss: 2.7669 (2.7963)  time: 0.504008  data: 0.257414  max mem: 8193
I20240923 18:48:21 215416 dinov2 helpers.py:102] Training  [  2090/160000]  eta: 19:56:30  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8559 (14.1321)  dino_local_crops_loss: 10.0827 (10.1366)  dino_global_crops_loss: 1.0083 (1.0140)  koleo_loss: -0.0001 (0.1853)  ibot_loss: 2.7668 (2.7962)  time: 0.495446  data: 0.250182  max mem: 8193
I20240923 18:48:25 215416 dinov2 helpers.py:102] Training  [  2100/160000]  eta: 19:55:47  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8604 (14.1308)  dino_local_crops_loss: 10.0823 (10.1363)  dino_global_crops_loss: 1.0087 (1.0140)  koleo_loss: 0.0016 (0.1844)  ibot_loss: 2.7677 (2.7960)  time: 0.393861  data: 0.160739  max mem: 8193
I20240923 18:48:29 215416 dinov2 helpers.py:102] Training  [  2110/160000]  eta: 19:55:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8580 (14.1295)  dino_local_crops_loss: 10.0815 (10.1361)  dino_global_crops_loss: 1.0085 (1.0140)  koleo_loss: -0.0017 (0.1835)  ibot_loss: 2.7677 (2.7959)  time: 0.406556  data: 0.170305  max mem: 8193
I20240923 18:48:35 215416 dinov2 helpers.py:102] Training  [  2120/160000]  eta: 19:56:52  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8582 (14.1282)  dino_local_crops_loss: 10.0837 (10.1359)  dino_global_crops_loss: 1.0083 (1.0140)  koleo_loss: -0.0020 (0.1826)  ibot_loss: 2.7667 (2.7958)  time: 0.504218  data: 0.262652  max mem: 8193
I20240923 18:48:39 215416 dinov2 helpers.py:102] Training  [  2130/160000]  eta: 19:56:08  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8585 (14.1269)  dino_local_crops_loss: 10.0837 (10.1356)  dino_global_crops_loss: 1.0085 (1.0139)  koleo_loss: -0.0022 (0.1818)  ibot_loss: 2.7666 (2.7956)  time: 0.499907  data: 0.262274  max mem: 8193
I20240923 18:48:43 215416 dinov2 helpers.py:102] Training  [  2140/160000]  eta: 19:55:29  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8549 (14.1257)  dino_local_crops_loss: 10.0827 (10.1354)  dino_global_crops_loss: 1.0082 (1.0139)  koleo_loss: -0.0025 (0.1809)  ibot_loss: 2.7665 (2.7955)  time: 0.404346  data: 0.169773  max mem: 8193
I20240923 18:48:48 215416 dinov2 helpers.py:102] Training  [  2150/160000]  eta: 19:55:05  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8548 (14.1244)  dino_local_crops_loss: 10.0824 (10.1351)  dino_global_crops_loss: 1.0079 (1.0139)  koleo_loss: -0.0035 (0.1800)  ibot_loss: 2.7667 (2.7954)  time: 0.417798  data: 0.173577  max mem: 8193
I20240923 18:48:53 215416 dinov2 helpers.py:102] Training  [  2160/160000]  eta: 19:56:30  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8555 (14.1232)  dino_local_crops_loss: 10.0821 (10.1349)  dino_global_crops_loss: 1.0079 (1.0138)  koleo_loss: -0.0020 (0.1792)  ibot_loss: 2.7659 (2.7952)  time: 0.502923  data: 0.253328  max mem: 8193
I20240923 18:48:58 215416 dinov2 helpers.py:102] Training  [  2170/160000]  eta: 19:55:56  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8542 (14.1219)  dino_local_crops_loss: 10.0804 (10.1346)  dino_global_crops_loss: 1.0081 (1.0138)  koleo_loss: -0.0022 (0.1784)  ibot_loss: 2.7652 (2.7951)  time: 0.495221  data: 0.252591  max mem: 8193
I20240923 18:49:02 215416 dinov2 helpers.py:102] Training  [  2180/160000]  eta: 19:55:22  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8505 (14.1207)  dino_local_crops_loss: 10.0804 (10.1344)  dino_global_crops_loss: 1.0081 (1.0138)  koleo_loss: -0.0037 (0.1775)  ibot_loss: 2.7657 (2.7950)  time: 0.413973  data: 0.174544  max mem: 8193
I20240923 18:49:06 215416 dinov2 helpers.py:102] Training  [  2190/160000]  eta: 19:55:00  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8532 (14.1194)  dino_local_crops_loss: 10.0821 (10.1341)  dino_global_crops_loss: 1.0083 (1.0138)  koleo_loss: -0.0039 (0.1767)  ibot_loss: 2.7666 (2.7948)  time: 0.422711  data: 0.178463  max mem: 8193
I20240923 18:49:12 215416 dinov2 helpers.py:102] Training  [  2200/160000]  eta: 19:56:45  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8510 (14.1182)  dino_local_crops_loss: 10.0817 (10.1339)  dino_global_crops_loss: 1.0081 (1.0137)  koleo_loss: -0.0039 (0.1759)  ibot_loss: 2.7666 (2.7947)  time: 0.518840  data: 0.266163  max mem: 8193
I20240923 18:49:16 215416 dinov2 helpers.py:102] Training  [  2210/160000]  eta: 19:55:49  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8481 (14.1170)  dino_local_crops_loss: 10.0800 (10.1336)  dino_global_crops_loss: 1.0082 (1.0137)  koleo_loss: -0.0046 (0.1751)  ibot_loss: 2.7647 (2.7946)  time: 0.495099  data: 0.249224  max mem: 8193
I20240923 18:49:20 215416 dinov2 helpers.py:102] Training  [  2220/160000]  eta: 19:55:34  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8508 (14.1158)  dino_local_crops_loss: 10.0826 (10.1334)  dino_global_crops_loss: 1.0083 (1.0137)  koleo_loss: -0.0054 (0.1743)  ibot_loss: 2.7653 (2.7944)  time: 0.410820  data: 0.167498  max mem: 8193
I20240923 18:49:24 215416 dinov2 helpers.py:102] Training  [  2230/160000]  eta: 19:54:45  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8523 (14.1146)  dino_local_crops_loss: 10.0815 (10.1332)  dino_global_crops_loss: 1.0080 (1.0137)  koleo_loss: -0.0036 (0.1735)  ibot_loss: 2.7651 (2.7943)  time: 0.415765  data: 0.173219  max mem: 8193
I20240923 18:49:30 215416 dinov2 helpers.py:102] Training  [  2240/160000]  eta: 19:56:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8495 (14.1135)  dino_local_crops_loss: 10.0809 (10.1330)  dino_global_crops_loss: 1.0085 (1.0136)  koleo_loss: -0.0050 (0.1727)  ibot_loss: 2.7650 (2.7942)  time: 0.481144  data: 0.248014  max mem: 8193
I20240923 18:49:34 215416 dinov2 helpers.py:102] Training  [  2250/160000]  eta: 19:55:21  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8491 (14.1123)  dino_local_crops_loss: 10.0817 (10.1327)  dino_global_crops_loss: 1.0086 (1.0136)  koleo_loss: -0.0057 (0.1719)  ibot_loss: 2.7651 (2.7940)  time: 0.486542  data: 0.254652  max mem: 8193
I20240923 18:49:38 215416 dinov2 helpers.py:102] Training  [  2260/160000]  eta: 19:54:46  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8491 (14.1111)  dino_local_crops_loss: 10.0829 (10.1325)  dino_global_crops_loss: 1.0085 (1.0136)  koleo_loss: -0.0057 (0.1711)  ibot_loss: 2.7644 (2.7939)  time: 0.407060  data: 0.175060  max mem: 8193
I20240923 18:49:42 215416 dinov2 helpers.py:102] Training  [  2270/160000]  eta: 19:54:18  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8522 (14.1100)  dino_local_crops_loss: 10.0853 (10.1323)  dino_global_crops_loss: 1.0088 (1.0136)  koleo_loss: -0.0051 (0.1703)  ibot_loss: 2.7639 (2.7938)  time: 0.415883  data: 0.177421  max mem: 8193
I20240923 18:49:48 215416 dinov2 helpers.py:102] Training  [  2280/160000]  eta: 19:55:51  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8539 (14.1089)  dino_local_crops_loss: 10.0831 (10.1321)  dino_global_crops_loss: 1.0085 (1.0136)  koleo_loss: -0.0040 (0.1696)  ibot_loss: 2.7639 (2.7936)  time: 0.508182  data: 0.261403  max mem: 8193
I20240923 18:49:52 215416 dinov2 helpers.py:102] Training  [  2290/160000]  eta: 19:55:09  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8513 (14.1077)  dino_local_crops_loss: 10.0804 (10.1319)  dino_global_crops_loss: 1.0082 (1.0135)  koleo_loss: -0.0038 (0.1688)  ibot_loss: 2.7651 (2.7935)  time: 0.497390  data: 0.254389  max mem: 8193
I20240923 18:49:56 215416 dinov2 helpers.py:102] Training  [  2300/160000]  eta: 19:54:39  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8512 (14.1066)  dino_local_crops_loss: 10.0815 (10.1316)  dino_global_crops_loss: 1.0084 (1.0135)  koleo_loss: -0.0049 (0.1681)  ibot_loss: 2.7656 (2.7934)  time: 0.409305  data: 0.168113  max mem: 8193
I20240923 18:50:00 215416 dinov2 helpers.py:102] Training  [  2310/160000]  eta: 19:53:57  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8528 (14.1055)  dino_local_crops_loss: 10.0825 (10.1314)  dino_global_crops_loss: 1.0088 (1.0135)  koleo_loss: -0.0057 (0.1673)  ibot_loss: 2.7656 (2.7933)  time: 0.408644  data: 0.165499  max mem: 8193
I20240923 18:50:06 215416 dinov2 helpers.py:102] Training  [  2320/160000]  eta: 19:55:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8512 (14.1044)  dino_local_crops_loss: 10.0825 (10.1312)  dino_global_crops_loss: 1.0086 (1.0135)  koleo_loss: -0.0059 (0.1666)  ibot_loss: 2.7648 (2.7931)  time: 0.484714  data: 0.245221  max mem: 8193
I20240923 18:50:11 215416 dinov2 helpers.py:102] Training  [  2330/160000]  eta: 19:55:02  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8512 (14.1033)  dino_local_crops_loss: 10.0835 (10.1310)  dino_global_crops_loss: 1.0087 (1.0135)  koleo_loss: -0.0057 (0.1658)  ibot_loss: 2.7640 (2.7930)  time: 0.509327  data: 0.263169  max mem: 8193
I20240923 18:50:14 215416 dinov2 helpers.py:102] Training  [  2340/160000]  eta: 19:54:11  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8527 (14.1023)  dino_local_crops_loss: 10.0839 (10.1308)  dino_global_crops_loss: 1.0085 (1.0134)  koleo_loss: -0.0043 (0.1651)  ibot_loss: 2.7622 (2.7929)  time: 0.416559  data: 0.172034  max mem: 8193
I20240923 18:50:19 215416 dinov2 helpers.py:102] Training  [  2350/160000]  eta: 19:53:40  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8470 (14.1012)  dino_local_crops_loss: 10.0820 (10.1306)  dino_global_crops_loss: 1.0082 (1.0134)  koleo_loss: -0.0046 (0.1644)  ibot_loss: 2.7627 (2.7928)  time: 0.400450  data: 0.163954  max mem: 8193
I20240923 18:50:24 215416 dinov2 helpers.py:102] Training  [  2360/160000]  eta: 19:55:00  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8469 (14.1001)  dino_local_crops_loss: 10.0822 (10.1304)  dino_global_crops_loss: 1.0081 (1.0134)  koleo_loss: -0.0065 (0.1637)  ibot_loss: 2.7636 (2.7926)  time: 0.497976  data: 0.251251  max mem: 8193
I20240923 18:50:29 215416 dinov2 helpers.py:102] Training  [  2370/160000]  eta: 19:54:28  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8440 (14.0990)  dino_local_crops_loss: 10.0818 (10.1302)  dino_global_crops_loss: 1.0079 (1.0134)  koleo_loss: -0.0069 (0.1630)  ibot_loss: 2.7630 (2.7925)  time: 0.497514  data: 0.253164  max mem: 8193
I20240923 18:50:33 215416 dinov2 helpers.py:102] Training  [  2380/160000]  eta: 19:54:03  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8437 (14.0980)  dino_local_crops_loss: 10.0799 (10.1300)  dino_global_crops_loss: 1.0080 (1.0133)  koleo_loss: -0.0084 (0.1622)  ibot_loss: 2.7625 (2.7924)  time: 0.418631  data: 0.181698  max mem: 8193
I20240923 18:50:37 215416 dinov2 helpers.py:102] Training  [  2390/160000]  eta: 19:53:17  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 16.0000 (16.0000)  total_loss: 13.8497 (14.0969)  dino_local_crops_loss: 10.0841 (10.1298)  dino_global_crops_loss: 1.0085 (1.0133)  koleo_loss: -0.0085 (0.1615)  ibot_loss: 2.7618 (2.7923)  time: 0.407304  data: 0.169819  max mem: 8193
